## 190816 Hadoop

## HDFS 관리

**#hadoop** **fs - 옵션**

- 파일 목록 보기 : ls, lsr
- 파일 용량 확인 : du, dus
- 파일 내용 보기 : cat, text
- 디렉토리 생성 : mkdir
- 파일 복사 : put, get, getmerge,  cp, copyFromLocal,  copyToLocal
- 파일 이동 : mv, moveFromLocal
- 카운트 값 조회 : count
- 파일삭제, 디렉토리 삭제 : rm,  rmr
- 파일의 마지막 내용 확인 : tail
- 권한 변경 : chmod, chown,  chgrp
- 0바이트파일 생성 : touchz
- 통계 정보 조회 : stat
- 복제 데이터 개수 변경 : setrep
- 휴지통 비우기 : expunge
- 파일 형식 확인 : test



![1565916256208](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565916256208.png)

![1565916265255](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565916265255.png)





**#안전모드**

- 하둡 실행 후 ^z 나 ^s 와 같이 비정상 종료를 할 경우 hadoop은 default로 safe모드로 진입하게 된다. 이 때, hdfs을 조작하면 다음과 같은 에러 메시지가 출력된다.
  - org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /output. Name node is in safe mode.

- 안전모드에서 파일 시스템 메터데이터로의 접근(디렉토리 목록 조회 같은)은 정상 동작한다. 만일 파일 읽기도 해당 블록이 클러스터에 있는 현재의 데이터 노드 상에 존재한다면 정상 동작한다. 그러나 파일 변경(쓰기, 삭제, 또는 이름 변경)은 항상 실패한다.

- 안전모드 진입과 해제
  -  hadoop dfsadmin -safemode get
  -  hadoop dfsadmin -safemode wait
  -  hadoop dfsadmin -safemode enter
  -  hadoop dfsadmin -safemode leave





**#도구**

- dfsadmin
  -  dfsadmin 도구는 HDFS 상태 정보를 조회하는 것 뿐만 아니라 HDFS 상에서 다양한 관리 동작을 수행하는 다목적 도구이다.

  - dfsadmin –help

![1565918981517](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565918981517.png)

- 파일 시스템 점검 : fsck
  - 모든 데이터 노드를 점검하여 사라지거나, 적게 또는 많이 복제된 블록을 찾아준다.
  - hadoop fsck / : 과잉 복제된 블록을 HDFS는 자동으로 삭제한다. 부족하게 복제된 블록은 목표 복제 수를 충족할 때까지 생성한다.

- hadoop dfsadmin -metasave 를 사용하면 복제되고 있는 블록에 대한 정보조회할 수 있다.
  - 잘못 복제된 블록(해당 블록의 복제본 모두가 같은 랙에 있을 경우)은 자동으로 잘못 복제된 블록을 재복제 한다.
  -  hadoop fsck /output/part-r-00000 -files -blocks -racks





**#로깅**

- log4j는 자바기반 로깅 유틸리티이다. 디버그용 도구로 주로 사용되고 있다.

- log4j의 최근 버전에 의하면 높은 등급에서 낮은 등급으로의 6개 로그 레벨을 가지고 있다. 설정 파일에 대상별(자바에서는 패키지)로 레벨을 지정이 가능하고 그 등급 이상의 로그만 저장하는 방식이다.

- 하둡은 log4j 로그 설정파일을 통해 로그 수준을 지정할 수 있다.
- log4j.properties 로그 레벨
  - FATAL , ERROR, WARN, INFO, DEBUG, TRACE

![1565919078303](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565919078303.png)

- 위 내용처럼 디폴트는 잡트래커나 태스크크래커의 로그 레벨 설정이 주석처리 되어 있습니다.

- 주석을 풀고 하둡을 재 시작 시키면 로그 레벨이 변경됩니다.



**#클러스터에서** **노드를** **추가하기**

1. include 파일에 새 노드의 네트워크 주소를 추가한다.

   dfs.hosts와 mapreduce.jobtracker.hosts.filename속성을 통해 하나의 공유 파일을 참조한다.

2. 네임노드에 허가된 데이터 노드 집합을 반영한다.

   $ hadoop dfsadmin -refreshNodes

3. 새로 허가된 태스크트래커 집합을 잡트래커에 반영한다.

   $ hadoop mradmin -refreshNodes

4. 새 노드가 하둡 제어 스크립트에 의해 장차 클러스터에서 사용될 수 있게 slaves 파일을 갱신한다.

5. 새로운 데이터 노드와 대스크 트래커를 시작한다.

6. 새로운 데이터 노드와 태스크 트래커가 웹 UI에 나타나는지를 확인한다.





**#클러스터에서** **노드를** **제거하기**  

  1.해제할 노드의 네트워크 주소를 exclude 파일에 추가한다. 이때 include 파일은 수정하지 않는다.

​	     hosts.include파일

​	     hosts.exclude 파일

​	     hdfs-site.xml 에 hosts와  hosts.exclude  property 설정 

2. 허가된 새로운 데이터 노드 집합을 가지고 네임노드를 갱신한다.

   $ hadoop dfsadmin -refreshNodes

3. 허가된 새로운 태스크 트래커 집합을 가지고 잡 트래커를 갱신한다.

   $ hadoop mradmin -refreshNodes

4. 웹 UI에 접속해서 해제할 데이터 노드의 관리 상태가 "Decommissinoning in Progress"로 변했는지 확인한다.

5. 모든 데이터 노드가 블록 복사를 완료하면 관리 상태가 "Decommissioned"로 변한다.

6. include 파일에서 해당 노드를 삭제하고 나서 실행한다.

   $ hadoop dfsadmin -refreshNodes

   $ hadoop mradmin -refreshNodes

7. salves 파일에서 해당 노드를 지운다..





**#DataNode**  **가용성**

- 블록 단위로 리클리케이션을 해서 데이터 가용성을 보장하므로 일부 DataNode가 고장 나도 데이터 처리를 계속 실행할 수 있다.



**#NameNode**  **가용성**

- Hadoop 2.0버전에서는 내장 기능으로 NameNode HA가 도입되었다 
   NameNode HA에서는 스탠바이 노드의 NameNode 프로세스도 사전에 스탠바이 모드로 가동되며, 블록 리포트가 액티브 노브와 스탠바이 노드 양쪽에 전송된다.

- 파일 시스템 메타데이터를 이중화하기 위해서 JournalNode라는 서버프로세스를 도입했다. Namenode가 JournalNode에 edits를 전송하는 구조는 Quorum journal Manager라 부르는 모듈이 담당한다.

- NameNode가 파일 시스템 메타데이터를 갱신할 때, 저널 로그를 각 Journal Node에 전송하다

- JournalNode는 홀수 대로 구성할 필요가 있다. JournalNode의 클라이언트는 NameNode이므로  JournalNode는 기본 구성 3대가 적당하다

- HA 클러스터로 실제로 운영하기 위해서는 클러스터 상태를 감시하여 장애 시에 페일오버를 실행할 기능이 필요하며, 이 기능을 제공하는 것이 ZKFC(ZooKeeper Failover Controller)라 불리는 모듈이다.





**#TaskTracker**  **가용성**

- Task 실행중에 장애가 발생할 경우, 해당 태스크를 다른 노드에서 재실행함으로써 Job 가용성을 보장한다.

- JobTracker와 TaskTrackers는 정기적으로 heartbeat 통신을 한다.

- mapred.tasktraker.expiry.interval : TaskTracker가 정상적으로 동작하지 않아 클러스터에서 제외처리가 발생하기까지의 시간 간격을 설정하는 속성 (기본값 10분)

- mapred.map.max.attempts , mapred.reduce.max.attempts :  클러스터에서 제외한 Task를 다른 TaskTracker에 할당해서 재실행하는 횟수의 최대치  (기본값 4)





**#JobTracker**  **가용성**

- JobTracker가 메모리 내에 가지고 있는 잡이나 태스크 상태 정보는 JobTracker가 다운된 시점에 없어져 버린다. JobTracker를 재시작하더라도 장애 시에 실행 중이었던 Job은 다시 실행해야 한다.

- JobTracker 정지 시에 실행 도중이었던 Job 정보를 HDFS 상에 있던 Job 디렉토리를 기반으로 복ㄱ하는 mapred.jobtracker.restart.recover 속성을 설정한다.

- JobTracker 장애 발생시에 는 스탠바이 노드에 페일오버한 후, HDFS 상에 있는 잡 정보를 이용해서 실행 중이었던 Job을 복구한다.  또한 클라이언트 측에도 에러 시에 다른 JobTracker에 대해 재시도하는 기능이 추가되었다.

- 장애 감지와 페일오버 제어는 ZKFC(ZooKeeper Failover Controller) 라 불리는 모듈을 통해 이루어진다.





## MapReduce Programming

**#MapReduce** **프레임워크는** **페타바이트** **이상의 대용량 데이터를 신뢰할 수 없는 컴퓨터로 구성**

**#된 클러스터 환경에서 병렬 처리를 지원하기 위해서 개발되었다.**

**#MapReduce 프레임워크는 함수형 프로그래밍에서 일반적으로 사용되는Map()과 Reduce() 함수 기반으로 주로 구성된다.**

- Map()은 (key, value) 쌍을 처리하여 또 다른 (key ,value) 쌍을 생성하는 함수

- Reduce()는 맵(map)으로부터 생성된 (key, list(value)) 들을 병합(merge)하여 최종적으로 list(value) 들을 생성하는 함수이

- 데이터 처리를 위한 프로그래밍 모델

- 분산컴퓨팅에 적합한 함수형 프로그래밍

- 배치형 데이터 처리 시스템

- 자동화된 병렬처리 및 분산처리

- Fault-tolerance(내고장성, 결함허용)

- 프로그래머를 위한 추상클래스



**#작업(Job)**

- 데이터 집합을 이용하여 Mapper와 Reducer를 실행하는 "전체 프로그램“

- 20개의 파일로부터 "Word Count"를 실행하는 것은 1개의 작업(Job)이다.



**#태스크(Task)**

- 1개의 데이터 조각을 처리하는 1개의 Mapper 또는 Reducer의 실행.

- 20개의 파일은 20개의 Map 태스크에 의해 처리된다.



**#태스크 시도(Task Attempt)**

- 머신 위에서 1개의 태스크를 실행하는 특정 시도.

- 최소한 20개의 Map 태스크 시도들이 수행된다. 서버 장애 시에는 더 많은 시도들이 수행된다.



**#Map**

- 어떤 데이터의 집합을 받아들여 데이터를 생성하는 프로세스.

- 주로 입력 파일을 한 줄씩 읽어서 filtering등의 처리를 수행한다.



**#Reduce**

- Map에 의해서 만들어진 데이터를 모아서 최종적으로 원하는 결과로 만들어 내는 프로세스

- 데이터 집약 처리

- 어떤 처리든 데이터는 키(key)와 밸류(value)의 쌍으로 이루어지고, 해당 쌍의 집합을 처리.

- 입력 데이터도 출력 데이터도  key-value의 집합으로 구성된다.

- Shuffle 

- Map 처리 후 데이터를 정렬해서, 같은 키를 가진 데이터를 같은 장소에 모은다.  

- 슬레이브 서버 간에 네트워크를 통한 전송이 발생한다.





**#Job Tracker** 

- 클라이언트로부터 작업요청을 받으면 실행한다.

- Task Tracker의 작업 할당 및 결과를 통합한다.

- Task Tracker의 상태 및 전체 작업 진행 상황 등을 지속적으로 감시한다.

- 마스터 노드에서 Job Tracker는 시작한다.

**#Task** **Tracker** 

- Task Tracker는 슬레이브 노드에서 실행된다.

- Task Tracker는 태스크를 실행할 자바 프로세스를 발생 시킨다.

- TaskTracker는 JobTracker가 할당한 태스크 관리 및 실행을 수행한다.

- 최대 몇 개의 태스크를 동시 수용할지는 사용자가 Hadoop 설정을 통해 지정할 수 있다.

- 한 TaskTracker에서 수행할 수 있는 최대 태스크 개수는 Map Task와 Reduce Task 별로 지정이 가능하다.

![1565920207418](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565920207418.png)







**#MapReduce 동작 과정**

![1565920408287](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565920408287.png)

1. job tracker가 mapper를 각 task tracker로 배분

2. task tracker는 자신이 보유한 데이터 청크를 대상으로 map 작업을 수행

3. 중간 결과는 로컬 스토리지에 저장 (partitioned, sorted)

4. 중간 결과를 reducer의 입력으로 전달

5. task tracker가 reducer를 수행

6. reducer 실행 후 결과 저장



![1565920428545](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565920428545.png)





**#데이터 흐름 : 1단계 Input & Map**

- MapReduce를 이용하여 할 수 있는 작업
  - 카운터
  - 입력파일 중 조건에 맞는 데이터의 수를 세는 일
  - 분산 grep
    - 파일에서 특정 문자열을 포함하는 행을 찾는 프로그램
  - 분산 sort
    - 입력 데이터를 임의의 순서로 정렬하는 것도 가능

![1565921322245](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921322245.png)



**#데이터 흐름 : 2단계 파티셔닝 & 셔플**

![1565921422708](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921422708.png)



**#데이터 흐름 : 3단계 Reduce & Output**

![1565921442180](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921442180.png)

![1565921447598](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921447598.png)



![1565921457013](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921457013.png)



![1565921462527](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921462527.png)



**#MapReduce** : 하둡분산파일시스템(HDFS) 위에서 운영되는 개발자를 위한 분산병렬처리 프레임워크

**#Hadoop MapReduce** **프로그래밍 요소**

- 데이터 타입
  - 맵리듀스 프로그램에서 키와 값으로 사용되는 데이터 타입
  - 반드시 WritableComparable 인터페이스를 구현해야 함

- InputFormat
  - 입력 스플릿을 맵 메서드의 입력 파라미터로 사용할 수 있도록 함

- Mapper
  - 키와 값으로 구성된 입력 데이터를 전달받아 데이터를 가공하고 분류해서 새로운 데이터 목록을 생성

- Partitioner
  - 맵 태스크의 출력 데이터가 어떤 리듀스 태스크로 전달될지 결정

- Reducer
  - 맵 태스크의 출력 데이터를 입력 데이터로 전달받아 집계 연산을 수행

- OutputFormat
  - setOutputFormatClass 메서드로 설정하는 맵 리듀스 잡의 출력 데이터 포맷





**#HDFS** **접근** **-** **FileSystem**

- org.apache.hadoop.fs.FileSystem

- 하둡에서 제공하는 파일 시스템을 추상화 한 클래스입니다.

- 로컬 파일 시스템이나 HDFS나 어떤 파일 시스템을 사용하든 반드시 FileSystem 클래스로 파일에 접근해야 합니다.

- 객체 생성
  - Configuration conf = new Configuration();
  - FileSystem hdfs = FileSystem.get(conf);

  - Path path = new Path("파일시스템 경로");

    또는

  - Path path = new Path("파일시스템 경로");

  - FileSystem fs = path.getFileSystem(getConf());

- 파일 시스템 경로
  - 상대경로는 /user/hadoop 디렉토리 기준



![1565921797104](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565921797104.png)



#이클립스에서 프로젝트 생성

- File -> New -> Project -> Java Project

#소스코드 작성

- 프로젝트 컨텍스트 메뉴(마우스 우클릭 메뉴) -> New -> Class

#컴파일

- 저장하면 자동 컴파일 됨

#Export 하여 JAR파일 생성

- jar파일로 만들어 실행해야 함

- Export 할 파일 또는 패키지 선택 후 마우스 오른쪽 버튼 클릭 -> Export
  - -> Java -> JAR file -> 저장될 디렉토리 선택 후 jar 파일명 입력
  - -> JAR 파일에 포함될 파일 확인 및 JAR file 대상 경로와 이름 확인 후 Next
  - -> Next -> Browse… 클릭해 Main 클래스 선택 후 Next -> Finish

#실행

- hadoop jar jar파일명 [패키지명을포함한main클래스이름] [옵션]





**#네임노드** **초기화**

(네임노드는 최초 한번만 실행하면 됨)

- $ cd /usr/local/hadoop-2.2.0/bin

- $ hdfs namenode -format

- 에러메시지가 있다면 환경설정파일이 잘못된 것임. 확인하고 수정한 다음 다시 실행시킬 것

![1565930505472](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565930505472.png)



**#방화벽 설정**

- http://master:50070/dfshealth.jsp 로 확인한 DFS Used% 항목이 100%로 되어 있으면 데이터 노드에 더 이상 저장 공간이 없거나 방화벽에 의해 막혀있는 경우이다.

- 방화벽 설정은 모든 노드에서 수행되어야 한다. 즉, datanode 뿐만 아니라 namenode 에서도 방화벽 규칙이추가되어야 한다.
  -  vi /etc/sysconfig/iptables
    - -A INPUT -s 192.168.0.0/24 -d 192.168.0.0/24 -j ACCEPT
    - -A OUTPUT -s 192.168.0.0/24 -d 192.168.0.0/24 -j ACCEPT
  - service iptables restart





**#TextInputFormat**

- FileInputFormat에서 상속받음

- 텍스트 파일 대상이며 .gz로 압축된 것도 처리.
  - 텍스트 라인 하나가 하나의 레코드에 해당.

- 해당 라인의 파일오프셋이 Key가 된다.

- Key의 타입은 LongWritable.

- 해당 라인 전체가 Value가 된다.

- Value의 타입은 Text.



=> Job 클래스의 setInputFormatClass 메서드로 다른 입력 포맷(KeyValueTextInputFormat, SequenceFileInputFormat)으로 변경할 수 있다.



=> 입력 파일들의 위치는 FileInptFormat 클래스의 addInputPath 메소드

로 지정 호출.



=> 하둡 프로그램의 입력과 출력은  HDFS 상의 파일(디렉토리)이 된다.



=> 맵의 출력 레코드들의 Key와 Value 타입은 Job 클래스의 setMapOutputKeyClass 메서드와 setMapOutputValueClass 메서드로 프레임워크에 알려주어야 한다.



=> Identity Mapper와 Identity Reducer 

- 맵이나 리듀스가 필요없는 경우에 사용

- 주어진 입력 레코드(Key, Value)를 그대로 출력 레코드로 내보내는 단순한 맵 클래스와 리듀스 클래스



=> 어떤 타입이 맵이나 리듀스에서 Key로 사용되기 위해서는 WritableComparable인터페이스를 지원해야 하고, Value로 사용되기 위해서는 Writable 인터페이스를 구현해야 한다.



=> Writable 인터페이스는 직렬화/역직렬화(serializable/deserializable)를 구현하는데 사용되는 메소드를 갖고 있다.

- 하둡의 Key/Value 레코드는 디스크에 저장되거나 네트워크를 타고 전달되어야 하므로 직렬화/역직렬화가 필요.

- 하둡은 RPC(Remote Procedure Call)를 이용해서 클러스터 내의 노드들 간에 통신을 수행하므로 직렬화/역직렬화가 필요.

- write 메서드 -  객체  직렬화(serializable)

- readFileds 메서드 – 객체 역직렬화( deserializable)



=> WritableComparable인터페이스는 객체들간의 비교를 가능하게 해주기 위한 자바의 Comparable 인터페이스가 추가된 인터페이스

- 하둡에서 맵과 리듀스에서 사용되는 키들은 소팅이 가능해야 한다.

- Comparable 인터페이스의 compareTo 메서드는 객체를 비교하여  순서를 정해주는 역할을 한다.



=> 하둡의 Key/Value로 사용되는 기본 타입들

|      타입       |                             설명                             |
| :-------------: | :----------------------------------------------------------: |
|      Text       | String에 해당하며 Text타입에서 String 타입의 값을 얻고자 하면 toString()를 호출 |
|   IntWritable   | Integer   또는 int에   해당,  int타입의   값을 얻으려면 get()를 호출 |
|  LongWritable   | Long이나 long에   해당,  long타입의   값을 얻으려면 get()를 호출 |
|  FloatWritable  | Float이나 float에   해당,  float타입의   값을 얻으려면 get()를 호출 |
| BooleanWritable | Boolean이나 boolean에   해당,  boolean타입의   값을 얻으려면 get()를 호출 |
|  ArrayWritable  | 하나의 값이 아니라 배열처럼 여러 개의 값을 한 번에 저장해야 할 경우   사용할 수 있는 있는 클래스 원소로 들어가는 값은 모두 동일한 타입이어야 한다. |
|  NullWritable   | 값이 없음을 나타내는 싱글톤 타입으로 Value의 값이 존재하지 않을 경우 사용, 자바 언어의   null과 같다. |
|                 |                org.apache.hadoop.io 레퍼런스                 |



- 실습 : SingleFileWriteRead.java

```java
package lab.hadoop.fileio;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

public class SingleFileWriteRead {
  public static void main(String[] args) {
	// 입력 파라미터 확인
	if (args.length != 2) {
		System.err.println("Usage: SingleFileWriteRead <filename> <contents>");
			System.exit(2);
		}

	try {
		// 파일 시스템 제어 객체 생성
		Configuration conf = new Configuration();
		FileSystem hdfs = FileSystem.get(conf);

		// 경로 체크
		Path path = new Path(args[0]);
		if (hdfs.exists(path)) {
			hdfs.delete(path, true);
		}

		// 파일 저장
		FSDataOutputStream outStream = hdfs.create(path);
		outStream.writeUTF(args[1]);
		outStream.close();

		// 파일 출력
		FSDataInputStream inputStream = hdfs.open(path);
		String inputString = inputStream.readUTF();
		inputStream.close();

		System.out.println("## inputString:" +inputString);
    System.out.println(path.getFileSystem(conf).getHomeDirectory()); //hdfs 홈 경로
    System.out.println(path.toUri()); //패스의 파일명
    System.out.println(path.getFileSystem(conf).getUri().getPath());

		} catch (Exception e) {
			e.printStackTrace();
		}
	}
}
```







**#KeyValueTextInputFormat**

- 하나의 레코드를 해석할 때 Key와 Value 사이에 TAB  문자와 같은 분리자가 있다고 가정한다.

- Tab이 아닌 다른 분리자를 사용해야 한다면 하둡 Job의 환경설정(Configuration) 인스턴스의 set 메서드를 호출하여 'key.value.separator.in.input.line' 프로퍼티의 값을 다른 분리자로 설정해야 한다.

- Key와 Value의 타입은 모두 Text가 된다.



**#SequenceInputFormat**

- 하둡의 고유 파일 포맷은 시퀀스 파일.

- 어떤 타입이든 Key와 Value로 사용 가능.

- MapFile을 읽는데도 사용할 수 있다.

- MapFile은 디렉토리이고 그 안에 인덱스 파일과 데이터 파일이 각각 시퀀스 파일의 형태로 존재한다.



**#MultipleInputs**

- 서로 다른 포맷의 입력 파일들간에 공통의 키가 존재하고 같은 키를 갖는 레코드들끼리 묶어서 조인을 수행하고 싶은 경우 사용

- 입력 파일의 경로에 따라 다른 입력 포맷과 맵 클래스를 지정할 수 있다.



**#Map Task** **수의 결정 방식**

- 주어진 입력 파일을 처리하기 위해 필요한 맵 태스크의 수는 프레임워크가 알아서 정한다.

- 입력 포맷이 주어진 입력 파일들을 처리하는데 몇 개의 맵 태스크가 필요한지 결정

- getSplits 메서드 - 주어진 모든 입력 파일들을 입력 파일 수와 입력 파일의 크기 정보를 바탕으로 InputSplit로 나눠서 그 조각들의 리스트를 리턴.

- InputSplit 마다 맵 태스크가 하나씩 할당 (하나의 데이터 블록마다 할당)

- 어떤 포맷들은 파일이 여러 블록으로 구성이 되어 있어도 블록별로 맵 태스크를 할당하는 것을 불허한다.  (TextInputFormat의 경우 텍스트 파일이 gzip 등으로 압축이 되어 있으면 전체 파일을 블록의 수와 관계 없이 하나의 맵 태스크에 지정해 버린다.)

- isSplitable 메서드는 블록 단위로 나눌 수 있는지 여부를 반환.



**#Combiner**

- Mini Reducer, Local Reducer

- 맵 태스크의 출력에 리듀스 코드를 먼저 적용해서 리듀스로 넘어가야 하는 데이터의 크기를 줄이는 역할을 담당.

- 맵 태스크와 리듀스 태스크 간의 네트워크 통신량을 최소화

- 작업의 순서를 달리해도 최종 결과물이 같은 잡이면 combiner를 적용할 수 있다. (교환의 법칙과 결합의 법칙이 만족되는 잡이라면 combiner를 적용할 수 있다.)

- Combiner를 적용할 수 있는 경우라면 리듀스 클래스를 그대로 컴바이너 클래스로 사용하는 형태를 가져가기를 권장.

- Combiner의 설정은 Job 클래스의 setCombinerClass 메서드로 가능.



**#Partitioner**

- 맵 태스크에서 나온 출력 레코드를 보고 어느 리듀스 태스크로 보낼지 결정

- 결과 레코드의 키 값을 해싱해서 그 해싱값을 리듀스 태스크의 수로 나누어 그 레코드가 어느 리듀스 태스크로 갈지 정해진다.

- 같은 키를 갖는 레코드들은 같은 리듀스 태스크로 보내지도록 한다.

- Job 클래스의 setPartitionerClass 메서드로 설정



**#Map** **출력** **버퍼링**

- 맵 태스크가 초기화될 대 원형 메모리 버퍼가 하나 만들어진다. 메모리 버퍼의 크기는  mapred-site.xml의 io.sort.mb 파라미터에 설정 (기본 100MB)

- 맵에서 출력 레코드가 생길 때마다 파티셔너 클래스를 통해 출력 레코드의 파티션 번호를 할당받고, 파티션 번호와  Key, Value 세가지 정보를 메모리 버퍼에 저장한다.

- 버퍼의 80%가 채워지면 버퍼의 내용을 디스크에 파일로 기록. Io.sort.spill.percent 파라미터로 버퍼의 퍼센트를 설정할 수 있다.

- 버퍼의 내용을 디스크로 써서 만들어지는 파일은 spill이라고 함.



**#Shuffle and Sorting**

![1565933179346](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933179346.png)



**#JobTracker**

![1565933196099](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933196099.png)

![1565933201769](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933201769.png)

![1565933206841](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933206841.png)





**#Single Reduce Task**

![1565933223418](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933223418.png)



**#Multiple Reduce Task**

![1565933238580](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933238580.png)



**#With No Reduce Task**

![1565933257196](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933257196.png)







**#MapReduce**

- 정의
  - MapReduce는 구글에서 분산 컴퓨팅을 지원하기 위한 목적으로 제작하여 2004년 발표한 소프트웨어 프레임워크로 HDFS에 저장된 파일이용

- 구성
  - 프레임워크는 함수형 프로그래밍에서 일반적으로 사용되는 Map()과  Reduce() 함수 기반으로 주로 구성.
  - Map() : (key, value) 쌍을 처리하여 또 다른 (key ,value) 쌍을 생성하는 함수 Reduce() : 맵으로부터 생성된 (key, list(value))들을 병합(merge)하여 최종적으로 list(value) 들을 생성하는 함수

- 목적
  - 프레임워크는 페타바이트(Petabyte) 이상의 대용량 데이터를 신뢰할 수 없는 컴퓨터로 구성된 클러스터 환경에서 병렬 처리를 지원하기 위해서 개발

- 단점
  - Java 언어를 습득할 필요. 



**#MapReduce** **특징**

- 데이터 처리를 위한 프로그래밍 모델

- 분산컴퓨팅에 적합한 함수형 프로그래밍

- 배치형 데이터 처리 시스템

- 자동화된 병렬처리 및 분산처리

- Fault-tolerance(내고장성, 결함허용)

- 상태 및 모니터링 툴들

- 프로그래머를 위한 추상클래스





**#Map 단계의 과정**

1. 마스터는 입력 파일을 복수의 단편으로 분할한 다음

2. 하나하나의 처리를 순차적을 워커에 할당한다.

3. 워커는 단편에 기록된 키와 값을 Map호출하여

4. Map은 새로운 키와 값을 출력한다.

5. 워커는 잠시 메모리상 중간파일로 저장하는데

6. 중간파일은 일시적으로만 사용하며, 효율을 높이기 위해 GFS가 아닌 로컬파일로 저장한다.

![1565933744345](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933744345.png)





**#Shuffle 단계의 과정**

1. 워커에서 중간파일이 생성이 되면 마스터를 경유해 Reduce워커에 위치 전달한다.

2. Reduce 워커는 네트워크를 경유해 중간파일을 가져오고 바로 셔플을 시작한다.

3. 중간파일에 기록된 키에 따라 모든 데이터가 정렬되며,

4. 중간파일이 작으면 메모리상에서 정렬, 크면 임시파일로 보낸다.

5. 중간 파일이 모일 때까지 셔플이 완료 되지 않기 때문에 Map이 계속 되는 한 셔플도 끝나지 않는다.

6. Map쪽에서 중간파일이 생성될 때마다 순차적으로 셔플이 이루어지고 모든 Map의 처리가완료가 되면 셔플도 끝난다.

![1565933809210](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565933809210.png)





**#Reduce 단계의 과정**

1. Reduce는 셔플이 끝난 그룹부터 차례로 시작한다.

2. Reduce에 건네진 키는 사전 순으로 작은 것부터 차례로 선택된다.

3. 중간파일에 기록된 키에 따라 모든 데이터가 정렬되며,

4. Reduce의 출력은 그룹별로 하나의 파일로서 GFS로 보내진다.

5. 그러므로 최종적으로 그룹의 수만큼 출력 파일이 만들어 진다.



#Zookeeper([http://zookeeper.apache.org](http://zookeeper.apache.org/)[/](http://zookeeper.apache.org/))

- 주키퍼는 분산 어플리케이션을 위한 고성능 코디네이션 서비스입니다.
  - 동물원 사육사와 같이 Hadoop(코끼리), chukwa(거북이), pig(돼지),hive(벌) 등을 관리하며, 분산처리 환경에서 다중의 서버에 집합을 묶어서 관리해주는 시스템에서 장애, 동기화 등 문제발생시 해결을 쉽게 하기 위한 것입니다.

- 주키퍼는 로드벨런서의 역할을 하는데, 이를 위해 다음과 같은 기능을 제공합니다.

  - 네임서비스 (서비스 룩업)를 통한 부하 분산

  - 분산 락이나 동기화 문제 해결
  - 클러스터 멤버십
  - 높은 가용성을 위한 장애복구

- 분산 시스템에서는 다음과 같은 문제를 생각하지 않을 수 없습니다.
  - 서버의 로드상태에 따라 동적으로 새로운 서버를 추가 할 수 있는가?

  - DB에 락을 건 서버가 장애가 발생하면 어떻게 되나?

  - Active/Standby 구조일 경우 액티브 서버의 장애 판단은?(만일 좀비 상태가 된다면?)

- 주키퍼는 다음 4가지의 노드들을 가지고 있습니다.

  - Znodes

  - Ephemeral Nodes (임시노드)

  - Sequence Nodes (순차적노드)
  - Watches





#Hadoop MapReduce 프로그래밍 요소

- 데이터 타입
  - 맵리듀스 프로그램에서 키와 값으로 사용되는 데이터 타입 클래스 입니다.
  -  데이터 타입 클래스는 개발자가 직접 구현할 수도 있으며, 반드시 WritableComparable 인터페이스를 구현해야 합니다.

  - 주요 데이터 타입 클래스 : BooleanWritable, ByteWritable, DoubleWritable, FloatWritable, IntWritable, LongWritable, Text, NullWritable

- InputFormat
  - 입력 스플릿을 맵 메서드의 입력 파라미터로 사용할 수 있도록 합니다.
  - 주요 InputFormat 클래스 : TextInputFormat, KeyValueTextInputFormat, NLineInputFormat,DelegatingInputFormat, CombineFileInputFormat, SequenceFileInputFormat

- Mapper
  - 입력 스플릿에서 key/value 쌍마다 실행됩니다.

  - 키와 값으로 구성된 입력 데이터를 전달받아 데이터를 가공하고 분류해서 새로운 데이터 목록을 생성합니다.

  - Mapper 클래스의 메서드는 4개가 있습니다.

    - protected void setup(Mapper.Context context) throws IOException

         => 태스크가 시작할 때 한번만 실행됩니다.

         => setup 메서드에는 자원획득, 초기화, 사용자 파라미터를 읽는 코드 등이 들어갑니다.

    - protected void map(KEYIN key, VALUEIN value, Mapper.Context context) throws IOException, InterruptedException

      ​	=> 컨텍스트에 key/value 쌍으로 저장하는 코드를 작성합니다.

    - protected void cleanup(Mapper.Context context) throws IOException

      ​	=> 태스크를 종료할 때 한번만 호출되므로, 자원을 반환하는 코드를 작성합니다.

    - public void run(Mapper.Context context) throws IOException, InterruptedException

      ​	=> 매퍼를 실행할 때 더 정교한 제어를 하기 위해 재정의 하는 메서드 입니다.

- Partitioner
  -  맵 태스크의 출력 데이터가 어떤 리듀스 태스크로 전달될지 결정합니다.
  -  setPartitionerClass() 메서드로 파티셔너 클래스를 설정합니다.

- Reducer

  - 맵 태스크의 출력 데이터를 입력 데이터로 전달받아 집계 연산을 수행하는 클래스입니다.

  - Reducer 클래스의 메서드는 4개가 있습니다.

    - protected void setup(Reducer.Context context) throws IOException

      ​	=> 태스크를 시작할 때 한번만 실행됩니다.

      ​	=> setup 메서드에는 Mapper의 setup 메서드와 같은 기능을 합니다. 자원획득, 초기화, 사용자

      ​		파라미터를 읽는 코드 등이 들어갑니다. 

    - protected void reduce(KEYIN key, VALUEIN value, Reducer.Context context) throws

      IOException, InterruptedException

      ​	=> 맵 태스크의 출력 데이터를 집계 연산을 수행하여 컨텍스트에 key/value 쌍으로 저장하는

      ​		코드를 작성합니다.

    - protected void cleanup(Reducer.Context context) throws IOException

      ​	=> 태스크를 종료할 때 한번만 호출됩니다. 자원을 반환하는 코드를 작성합니다.

    - public void run(Reducer.Context context) throws IOException, InterruptedException

      ​	=> 리듀서가 실행될 때 더 정교한 제어를 하기 위해 재정의 하는 메서드입니다.

- OutputFormat
  - 맵 리듀스 잡의 출력 데이터 포맷 클래스입니다.
  - setOutputFormatClass 메서드로 출력 데이터 포맷을 설정합니다.
  - 주요 클래스 : TextOutputFormat, SequenceFileOutputFormat, SequenceFileAsBinaryOutputFormat, FilterOutputFormat, LazyOutputFormat, NullOutputFormat



#HDFS 접근 - FileSystem

- org.apache.hadoop.fs.FileSystem

  - 하둡에서 제공하는 파일 시스템을 추상화 한 클래스입니다.

  - 로컬 파일 시스템이나 HDFS나 어떤 파일 시스템을 사용하든 반드시 FileSystem 클래스로 파일에 접근해야 합니다.

- 객체 생성

```java
Configuration conf = new Configuration();
FileSystem hdfs = FileSystem.get(conf);
Path path = new Path("파일시스템 경로");
 또는
Path path = new Path("파일시스템 경로");
FileSystem fs = path.getFileSystem(getConf());
```



- 파일 시스템 경로 : 상대경로는 /user/hadoop 디렉토리 기준

- 주요 메소드
  - public static FileSystem get(Configuration conf)
  - append(), concat()
  - copyFromLocalFile(), copyToLocalFile()
  - create(), delete(), mkdir(), rename()
  - getHomeDirectory(), getName(), getLength(), getWorkingDirectory()
  - exists(), isDirectory(), isFile()
  - listFiles()



#WordCount 프로그래밍 순서

1. 매퍼 클래스 작성

- Mapper 클래스를 상속받고 map() 메서드 재정의

-  map() 메서드 인자로 넘겨진 key와 value를 분석하여 context 객체를 통해 출력(write) 합니다.

2. 리듀서 클래스 작성

- Recuder 클래스를 상속받고 reduce() 메서드 재정의

- 매퍼의 결과가 셔플되고 각 키의 값은 Iterable 객체로 생성되어 리듀서의 입력으로 됩니다.

- reduce() 메서드 인자로 넘겨진 Iterable values를 카운트 하여 context 객체를 통해 출력(write) 합니다.

3. 드라이버 클래스 작성

-  Job 객체 생성(Job job = new Job("WordCount");

-  Job 객체에 맵리듀스 잡의 실행 정보 설정.

- 맵리듀스 잡 실행(job.waitForComplete);

4. Jar 파일로 Export(메인 클래스 지정해 주면 실행 시 편합니다)

- 패키지 선택 후 마우스 오른쪽 버튼 클릭

  => Export ->Java/JAR file 선택 후 Next

  => JAR 파일명 입력 후 Next -> Next -> Main class 선택 후 Finish

5. 샘플 텍스트 파일 작성

6. 샘플 텍스트 파일 HDFS에 업로드

- hadoop fs -put input.txt input.txt

- HDFS에 output 디렉토리 생성

7. 실행

- hadoop jar WordCount.jar input.txt output

- hadoop fs -cat /output/part-r-00000



#Mapper

- org.apache.hadoop.mapreduce.Mapper

  public class Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Object

- 메서드

  ​    protected void setup(Context context) throws IOException, InterruptedException

  ​    protected void map(KEYIN key, VALUEIN value, Context context) throws IOException, InterruptedException

  ​    protected void cleanup(Context context) throws IOException, InterruptedException

  ​    public void run(Context context) throws IOException, InterruptedException	

- 내부 클래스

​    org.apache.hadoop.mapreduce.Mapper.Context





#Reducer

- org.apache.hadoop.mapreduce.Reducer

  ​    public class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Object

- 메서드

  ​    protected void setup(Context context) throws IOException, InterruptedException

  ​    protected void reduce(KEYIN key, Iteravle<VALUEIN> values, Context context) throws IOException, InterruptedException 

  ​    protected void cleanup(Context context) throws IOException, InterruptedException

  ​    public void run(Context context) throws IOException, InterruptedException

- 내부 클래스

  ​    org.apache.hadoop.mapreduce.Reducer.Context

 

#드라이버

: 맵리듀스 잡에 대한 실행 정보를 설정하고, 맵리듀스 잡을 실행합니다.

- 실행 단계

1. 잡 객체를 생성합니다.

      Job job = new Job(conf, "잡 이름");

2. 잡 객체에 맵리듀스 잡의 실행 정보를 설정합니다.

      job.setJarByClass(WordCount.class);

      job.setMapperClass(WordCountMapper.class);

      job.setReducerClass(WordCountReducer.class);

      job.setInputFormat(TextInputFormat.class);

      job.setOutputFormat(TextOutputFormat.class);

      job.setOutputKeyClass(Text.class);

      job.setOutputValueClass(TextOutputFormat.class);

3. 맵리듀스 잡을 실행합니다.

   ​    job.waitForCompletion(true);



#WordCount 실행시 출력 로그

- 잡/리듀스 처리 과정이 로그로 출력됨

- 파일 출력 포맷 카운터

- 출력된 바이트 수

- 파일시스템 카운터

- HDFS 입/출력 바이트 수

- 파일 입력 포맷 카운터

- 입력 바이트 수

- 맵리듀스 프레임웍

- 맵 입력 레코드 수, 맵 출력 바이트 수, 힙 메모리 사용량, CPU 사용 시간

- 리듀스 입력 수, 리듀스 입력 그룹 수, 리듀스 출력, 맵 출력 레코드 수

- 브라우저에서 잡트래커 확인 http://master:50030/jobtracker.jsp 





- 실습 : WordCountMapper.java

```java
package lab.hadoop.wordcount;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable>{
	private final static IntWritable one = new IntWritable(1);
	private Text word = new Text();
	

@Override
	protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		// TODO Auto-generated method stub
		super.map(key, value, context);
		StringTokenizer itr = new StringTokenizer(value.toString());
		while(itr.hasMoreTokens()) {
			word.set(itr.nextToken());
			context.write(word, one);
		
			}
	}
}
```



- WordCountReducer.java

```java
package lab.hadoop.wordcount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WordCountReducer extends
			Reducer<Text, IntWritable, Text, IntWritable>  {
		private IntWritable result = new IntWritable();

		@Override
		protected void reduce(Text key, Iterable<IntWritable> values,
				Context context) throws IOException, InterruptedException {
			int sum = 0;
			for (IntWritable val : values) {
				sum += val.get();
			}
			result.set(sum);
			context.write(key, result);
		}
}
```



