# 190911 R

## I. 워드클라우드

> 워드 클라우드(word cloud) : 특정 주제와 관련된 키워드의 색상과 크기, 글자모음 형태를 활용해 주제를 쉽고 빠르게 인식할 수 있는 시각화 기법

### 1. API 신청

- https://developers.naver.com/products/search/ 접속 Open API 신청
- [Products]-[서비스 API]-[검색] > 오픈 API 이용 신청 > 로그인
- 애플리케이션 이름 설정, WEB 설정 , 임의의 URL 입력 , 애플리케이션 등록 하기
- Client ID와 Client Secret 발급



### 2. 들어가기

- 네이버 Open API의 WEB 방식 호출은 API URL 뒤에 요청변수들을 "&" 기호로 연결해 전송하는 GET방식을 사용

[블로그 검색을 위한 API URL과  요청 변수]

https://openapi.naver.com/v1/search/blog.xml

- 요청변수 query는 string타입으로 필수이며 검색을 원하는 문자열(UTF-8로 인코딩)
- 요청변수 display는 integer타입으로 기본값 10, 최대값 100으로  검색 결과 출력 건수
- 요청변수 start는 integer타입으로 기본값 1, 최대값 1000으로 검색 시작 위치
- 요청변수 sort는 string타입으로 기본값 sim, date로 정렬 옵션:sim(유사도순), date는 날짜순

예) "RStudio"로 검색된 블로그 100개에 대해 첫 페이지부터 유사도순으로 정렬해 정보를 받기
https://openapi.naver.com/v1/search/blog.xml?query=Rstudio&display=100&start=1&sort=sim

- 결과값은 블로그 제목과 요약 내용, 작성자 이름 등 다양한 정보들이 XML 형식으로 제공



### 3. 실습

```R
#기본 URL
urlStr <- "https://openapi.naver.com/v1/search/blog.xml?"
#검색어 설정 및 UTF-8 URL 인코딩
searchString <- "query=코타키나발루"
#UTF-8 인코딩
searchString <- iconv(searchString, to="UTF-8")
#URL 인코딩
searchString <- URLencode(searchString )
searchString

#나머지 요청 변수 : 조회 개수 100개, 시작페이지 1, 유사도순 정렬
etcString <- "&display=100&start=1&sort=sim"

#URL조합
reqUrl <- paste(urlStr, searchString, etcString, sep="")
reqUrl

#get방식으로 URL을 호출하기 위해 httr패키지의 GET함수 활용
library(httr)
clientID <- 클라이언트ID 
clientSecret <- 클라이언트 secret

#인증정보는 add_headers에 담아 함께 전송
apiResult <- GET(reqUrl, add_headers("X-Naver-Client-Id"=clientID
                          , "X-Naver-Client-Secret"=clientSecret))
apiResult    #응답코드 status가 200이면 정상


# Open API의 결과 구조 확인 (UTF-8로 인코딩된 XML 형식)
str(apiResult)   #XML응답값은 "content"에 담겨 있습니다.

apiResult$content
str(apiResult$content)  

#raw형식이므로 rawToChar()를 활용해 문자로 변환
result <- rawToChar(apiResult$content)
result

Encoding(result) <- "UTF-8"  # UTF-8로 인코딩
result   #블러그 링크, 제목, 이름, 요약정보등을 제공
```



### 4. 함수 활용하기

#### 1) gsub()

> 워드 클라우드에 표현할 단어를 추출하기 전에 문자열을 치환하는 gsub 함수를 활용해 불필요한 XML관련 태그(tag)와 특수문자 제거
>
> - gsub(pattern, replacement, x, ignore.case)
>
> 변환 전 문자열(정규표현식 가능), 변환 후 문자열, 변환할 문자열 벡터, 대소문자 무시 여부

- gsub()는 고정된 문자열뿐 아니라 정규표현식을 통해 특정 패턴의 문자열들도 치환할 수 있다.
  - 패턴문자  \\w 는 '_'를 포함한 문자와 숫자_
  - 패턴문자  \\W 는  \\w 의 반대의미 '_'와 문자와 숫자를 제외한 기호패턴문자  \\d 는  숫자
  - 패턴문자  \\D 는  숫자를 제외한 기호와 문자
  - 패턴문자 []는 대괄호 안의 문자 중 한 개를 의미
  - 패턴문자 [^]는 대괄호 안의 문자가 없는 패턴을 의미

```R
> gsub("ABC", "***", "ABCabcABC")  # ABC를 ***로 변환
[1] "***abc***"
> gsub("ABC", "***", "ABCabcABC", ignore.case=T)
[1] "*********"

> x<-c("ABCabcABC", "abcABCabc")
> gsub("ABC", "***", x) 
[1] "***abc***" "abc***abc"

> gsub("b.n", "***", "i love banana")  
[1] "i love ***ana"
> gsub("b.*n", "***", "i love banana") 
[1] "i love ***a"
> gsub("[bn]a", "***", "i love banana") 
[1] "i love *********"
> gsub("010-[0-9]{4}-[0-9]{4}", "010-****-****", "내 폰번호는 010-1234-6789") 
[1] "내 폰번호는 010-****-****"
> gsub("010-\\d{4}-\\d{4}", "010-****-****", "내 폰번호는 010-1234-6789")
[1] "내 폰번호는 010-****-****" 

refinedStr <- result
#XML 태그를 공란으로 치환
refinedStr <- gsub("<\\/?)(\\w+)*([^<>]*)>", " ", refinedStr)
refinedStr

#단락을 표현하는 불필요한 문자를 공란으로 치환
refinedStr <- gsub("[[:punct:]]", " ", refinedStr)
refinedStr

#영어 소문자를 공란으로 치환
refinedStr <- gsub("[a-z]", " ", refinedStr)
refinedStr

#숫자를 공란으로 치환
refinedStr <- gsub("[0-9]", " ", refinedStr)
refinedStr

#여러 공란은 한 개의 공란으로 변경
refinedStr <- gsub(" +", " ", refinedStr)
refinedStr 
```



-----

## II. KoNLP (한글 자연어 분석 패키지)

- extractNoun()는 입력받은 문장에서 단어를 추출해 벡터로 반환
  - extractNoun( "안녕하세요 오늘은 기분 좋은 하루 입니다.")

### 1. 연습하기

```R
install.packages("KoNLP")
library(KoNLP)
library(rJava)

> nouns<- extractNoun( refinedStr )
> str(nouns)
 chr [1:3089] "UTF" "N" "O" "API" ...
> nouns[1:40]
 [1] "UTF"          "N"           
 [3] "O"            "API"         
 [5] "코타키나발루" "N"           
 [7] "S"            "R"           
 [9] "B"            "D"           
[11] "W"            "S"           
[13] "B"            "D"           
[15] "코타키나발루" "맛집"        
[17] "리앙"         "팬"          
[19] "씨푸드"       "L"           
[21] "F"            "S"           
[23] "R"            "L"           
[25] "N"            "이번"        
[27] "코타키나발루" "여행"        
[29] "식사"         "대부분"      
[31] "숙소"         "해결"        
[33] "코타키나발루" "시내"        
[35] "식사"         "두"          
[37] "번"           "뿐"          
[39] "두"           "번" 

#길이가 1인 문자를 제외
nouns <-nouns[nchar(nouns) > 1]

#제외할 특정 단어를 정의
> excluNouns <- c("코타키나발루", "얼마" , "오늘", "으로", "해서", "API", "저희", "정도")
> nouns  <- nouns [!nouns  %in% excluNouns ]
> nouns[1:40]
 [1] "UTF"          "맛집"        
 [3] "리앙"         "씨푸드"      
 [5] "이번"         "여행"        
 [7] "식사"         "대부분"      
 [9] "숙소"         "해결"        
[11] "시내"         "식사"        
[13] "식사"         "자스민"      
[15] "마사지"       "마사지"      
[17] "건물"         "가족"        
[19] "여행"         "계획"        
[21] "일정"         "정리"        
[23] "군데"         "후보지"      
[25] "선택"         "말레이시아"  
[27] "처음"         "티켓팅부터"  
[29] "우리"         "휴가지는"    
[31] "출처"         "트리플"      
[33] "여행"         "똑띠쥰"      
[35] "더수트라하버" "마젤란"      
[37] "퍼시픽"       "마리나"      
[39] "클럽"         "수영장"  

#빈도수 기준으로 상위 50개 단어 추출
> wordT <- sort(table(nouns), decreasing=T)[1:50]
> wordT
nouns
        여행         호텔   코타두드림 
          97           29           23 
        맛집   달려라포티       마사지 
          21           20           20 
  말레이시아         자유         시간 
          19           18           16 
      이야기         조식         현지 
          15           15           15 
      모스크         시작       여행사 
          14           14           14 
        이번         선셋       수영장 
          14           13           13 
        우리         일상         투어 
          13           13           13 
  수트라하버         이용         추천 
          12           12           12 
        공항         도착 들려드릴게요 
          11           10           10 
        쇼핑         일정         일차 
          10           10           10 
        사진         숙소     이마고몰 
           9            9            9 
        휴가       리조트     바다낚시 
           9            8            8 
      섬투어         위치         커피 
           8            8            8 
      휴양지       라운지 메리어트호텔 
           8            7            7 
      블로그         블루         석양 
           7            7            7 
        시내         여름       유잇청 
           7            7            7 
        이곳         가족 
           7            6 
```

![1](190911%20R.assets/1-1568176388546.JPG)



### 2. 실습하기

```R

```







-----

## III. 워드클라우드2

> - wordcloud2 패키지 
>   - wordcloud2 (data, size, shape) 
>
> - 단어와 빈도수 정보가 포함된 데이터프레임 또는 테이블, 글자 크기, 워드 클라우드의 전체 모양(circle:기본값, cardioid, diamond, triangle, star등)

```R
install.packages("wordcloud2")
library(wordcloud2)
wordcloud2(wordT, size=3, shape="diamond")
```



----

## IV. 영문서 형태소 분석 및 워드클라우드

- 패키지 설치 및 적용

```R
install.packages("tm") # 텍스트 마이닝을 위한 패키지
install.packages("SnowballC") # 어간 추출을 위한 패키지
# install.packages("wordcloud") # word-cloud generator
install.packages("RColorBrewer") # color palettes

library(tm)
library(SnowballC)
# library(wordcloud)
library(RColorBrewer)
```



- 파일 불러오고 문자영 벡터 생성

```R
> filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
> text <- readLines(filePath)
> str(text)
 chr [1:46] "" ...

# VectorSource() 함수는 문자형 벡터를 만든다.
> docs <- Corpus(VectorSource(text))
> head(docs)
<<SimpleCorpus>>
Metadata:  corpus specific: 1, document level (indexed): 0
Content:  documents: 6
```



- 텍스트의 특수 문자 등을 대체하기 위해 tm_map() 함수를 사용해 변
  - "/", "@" 및 "|"을 공백으로 바꾼다.

```R
> toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
> docs <- tm_map(docs, toSpace, "/")
> docs <- tm_map(docs, toSpace, "@")
> docs <- tm_map(docs, toSpace, "\\|")
> head(docs)
<<SimpleCorpus>>
Metadata:  corpus specific: 1, document level (indexed): 0
Content:  documents: 6                  
```



- 변환 및 제거

```R
# 소문자로 변환
docs <- tm_map(docs, content_transformer(tolower))
# 수치 데이터 제거
docs <- tm_map(docs, removeNumbers)
# 영어 불용어 제거
docs <- tm_map(docs, removeWords, stopwords("english"))

# 벡터 구조로 사용자가 직접 불용어  설정 , 제거
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 

# 문장 부호 punctuations
docs <- tm_map(docs, removePunctuation)

# 공백 제거
docs <- tm_map(docs, stripWhitespace)

# 텍스트 형태소 분석
docs <- tm_map(docs, stemDocument)
```



- wordcloud 생성

```R
# 문서 매트릭스는 단어의 빈도를 포함하는 테이블입니다. 
# 열 이름은 단어이고 행 이름은 문서입니다. 
# text mining 패키지에서 문서 매트릭스를 생성하는 함수 사용
> dtm <- TermDocumentMatrix(docs)
> m <- as.matrix(dtm)
> v <- sort(rowSums(m),decreasing=TRUE)
> d <- data.frame(word = names(v),freq=v)
> head(d, 10)
           word freq
div         div  107
href       href   57
french   french   50
classfa classfa   36
wiki       wiki   33
fafil     fafil   30
src         src   27
var         var   21
span       span   20
script   script   19


> set.seed(1234)
> wordcloud(words = d$word, freq = d$freq, min.freq = 1,
            max.words=200, random.order=FALSE, rot.per=0.35, 
            colors=brewer.pal(8, "Dark2"))
```

![2](190911%20R.assets/2.JPG)



-----

## V. ggplot2 패키지

> ggplot2는 시각화 1순위 패키지로, 기본적으로 ggplot()을 이용해 틀을 만들고, 그 안에 다양한 이미지 객체 레이어를 포개는 방식으로 그래프를 표현한다.



### 1-1. 기본 사용법

#### 1) 그래프 기본 틀 만들기

```R
> str(airquality)
'data.frame':	153 obs. of  6 variables:
 $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...
 $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...
 $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...
 $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...
 $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...
 $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...
> ggplot(airquality, aes(x=Day, y=Temp))  # x축은 Day 열, y축은 Temp 열로 맵핑
```



### 1-2. 산점도, geom_point() 함수

- 맵핑을 위해 작성한 ggplot() 함수 뒤에 + geom_point()만 추가로 입력하면 된다. ( ) 안에 size나 color 등의 추가옵션을 지정할 수 있다.

```R
> ggplot(airquality, aes(x=Day, y=Temp)) + geom_point(size=3, color="red")
```

![11](190911%20R.assets/11.JPG)



### 1-3. 꺾은선 그래프, geom_line() 함수

```R
> ggplot(airquality, aes(x=Day, y=Temp)) + geom_line()
```



- 그래프에 그래프 더하기

```R
> ggplot(airquality, aes(x=Day, y=Temp)) + geom_line() + geom_point()
```

![12](190911%20R.assets/12.JPG)



### 1-4. 막대 그래프, geom_bar() 함수

> 산점도와 꺾은선 그래프에서는 aes() 함수를 이용해 x축과 y축을 모두 지정했지만, 빈도를 파악하는 막대그래프에서는 x축만 지정하면 된다.

```R
# mtcars 데이터셋에서 cyl 열에 있는 실린더 종류별로 빈도수 확인해보기
> ggplot(mtcars, aes(x=cyl)) + geom_bar(width=0.5)
```

![13](190911%20R.assets/13.JPG)

#### 1) 빈 범주는 제외하고 확인하기

```R
> ggplot(mtcars, aes(x=factor(cyl))) + geom_bar(width=0.5)
```

![14](190911%20R.assets/14.JPG)

#### 2) 누적 막대그래프

```R
# cyl 종류별 gear 빈도 누적 막대그래프
> ggplot(mtcars, aes(x=factor(cyl))) +
    geom_bar(aes(fill=factor(gear)))
```

![15](190911%20R.assets/15.JPG)



#### 3) 누적 막대그래프로 선버스트 차트 그리기

- 누적막대그래프로 작성한 코드 맨 뒤에 + coord_polor()를 추가하면 된다.

```R
> ggplot(mtcars, aes(x=factor(cyl))) +
    geom_bar(aes(fill=factor(gear))) +
	coord_polor()
```

![16](190911%20R.assets/16.JPG)



### 1-5. 상자 그림 & 히스토그램

#### 1) geom_boxplot() 함수

> aes() 함수 안에 box로 그룹 지어 열을 설정해야 한다

```R
# airquality에서 Day 열을 그룹지어, 날짜별 온도 상자 그림을 그림
> ggplot(airquality, aes(x=Day, y=Temp, group=Day)) + geom_boxplot()
```

![17](190911%20R.assets/17.JPG)



#### 2) geom_histogram() 함수

```R
# airquality에서 Temp의 히스토그램
> ggplot(airquality, aes(Temp)) + geom_histogram(binWidth=1) # binWidth로 폭 지정
```

![18](190911%20R.assets/18-1568180532106.JPG)







> ggplot2 패키지에는 그래프를 그리는 함수뿐만 아니라 도형이나 텍스트 같은 다양한 객체를 그리는 함수도 포함돼 있다. 그래프에 선이나 도형을 추가하면 그래프의 가독성도 높아지고 중심 내용을 더 명확하게 표현할 수 있어 실무에서도 많이 이용한다.

### 2-1. 직선 그리기

```R
# 패키지 설치 및 적용
install.packages("ggplot2")
library(ggplot2)

# 데이터 속성 파악
> str(economics)
Classes ‘spec_tbl_df’, ‘tbl_df’, ‘tbl’ and 'data.frame':	574 obs. of  6 variables:
 $ date    : Date, format:  ...
 $ pce     : num  507 510 516 512 517 ...
 $ pop     : num  198712 198911 199113 199311 199498 ...
 $ psavert : num  12.6 12.6 11.9 12.9 12.8 11.8 11.7 12.3 11.7 12.3 ...
 $ uempmed : num  4.5 4.7 4.6 4.9 4.7 4.8 5.1 4.5 4.1 4.6 ...
 $ unemploy: num  2944 2945 2958 3143 3066 ...
```



#### 1) 사선, geom_abline() 함수

> x축 또는 y축과 만나는 값인 절편과 기울기를 설정해 그래프에 사선을 그릴 때 사용한다

```R
> ggplot(economics, aes(x = date, y = psavert)) +	# x축을 date, y축을 psavert로 맵핑
    geom_line() +									# 꺾은선 그래프 그리기
    geom_abline(intercept = 12.18671, slope = -0.0005444)
# 절편 12.18671, 기울기 -0.0005444로 사선 그리기
```

![3](190911%20R.assets/3.JPG)



#### 2) 평행선, geom_hline() 함수

> 평행선을 그릴 때 사용하며, 옵션으로 y축의 절편 값을 입력해야 한다.

```R
> ggplot(economics, aes(x = date, y = psavert)) +		# x축을 date, y축을 psavert로 맵핑
    geom_line() +										# 꺾은선 그래프 그리기
    geom_hline(yintercept = mean(economics$psavert))	# psavert 평균 값으로 평행선 그리기
# yintercept옵션으로 y축의 절편 값을 지정할 수 있다.
```

![4](190911%20R.assets/4.JPG)



#### 3) 수직선, geom_vline() 함수

> 수직선을 그릴 때 사용하며 옵션으로 x축 절편 값을 입력해야 한다.

```R
# 개인 저축률(psavert)이 가장 낮은 시기를 바로 알 수 있도록 수직선 그리기

# 개인 저축률이 최솟값일 때의 날짜(date)를 구해 x_inter 변수에 할당
> x_inter <- filter(economics, psavert==min(economics$psavert))$date
> ggplot(economics, aes(x=date, y=psavert)) +
    geom_line() +
    geom_vline(xintercept = x_inter)
```

![5](190911%20R.assets/5.JPG)



### 2. 텍스트 입력 및 도형 그리기

#### 1) 텍스트, geom_text() 함수

그래프에 텍스트를 입력할 때 사용. 범례나 제목과 달리 그래프 위에 직접 표현된다.

- geom_text(aes(label = 라벨명, vjust = 세로 위치, hjust = 가로 위치))

```R
# airquality 데이터 셋으로 날짜별 온도를 산점도로 표현하고 각 점에 온도를 표시해보기

> ggplot(airquality, aes(x=Day, y=Temp)) +	# x축을 Day, y축을 Temp로 맵핑
    geom_point() +	# 산점도 그리기
    geom_text(aes(label=Temp, vjust=0, hjust=0))	# 각 점에 Temp 값 입력
```

![6](190911%20R.assets/6.JPG)



#### 2) 도형 및 화살표, annotate() 함수

> 그래프 위에 사각형이나 화살표 등으로 특정 영역을 강조할 때 사용
>
> - annotate ( "모양", xmin = x축 시작, xmax = x축 끝, ymin = y축 시작, ymin = y축 끝)

```R
# mtcars 데이터셋을 이용해 무게와 연비를 기준으로 산점도를 그리고 주목할 지점에 사각형 그리기
> ggplot(mtcars, aes(x=wt, y=mpg)) +	# x축을 wt, y축을 mpg로 맵핑
    geom_point() +	# 산점도 그리기
    annotate("rect", xmin=3, xmax=4, ymin=12, ymax=21, alpha=0.5, fill="skyblue")
# x축 3~4, y축 12~21 위치에 하늘색(skyblue)dml 투명한(alpha=0.5) 사각형(rect) 그리기
```

![7](190911%20R.assets/7.JPG)



- 위의 그래프에 화살표까지 추가하기

```R
> ggplot(mtcars, aes(x=wt, y=mpg)) +
    geom_point() +
    annotate("rect", xmin=3, xmax=4, ymin=12, ymax=21, alpha=0.5, fill="skyblue") +
    annotate("segment", x=2.5, xend=3.7, y=10, yend=17, color="orange", arrow=arrow())
```

![8](190911%20R.assets/8.JPG)



- 위의 그래프에 레이블까지 추가하기

```R
> ggplot(mtcars, aes(x=wt, y=mpg)) +
    geom_point() +
    annotate("rect", xmin=3, xmax=4, ymin=12, ymax=21, alpha=0.5, fill="skyblue") +
    annotate("segment", x=2.5, xend=3.7, y=10, yend=17, color="orange", arrow=arrow()) +
    annotate("text", x=2.5, y=10, label="point")
```

![9](190911%20R.assets/9.JPG)



### 3. 그래프 제목 및 축 제목을 추가하고 디자인 테마 적용하기

#### 1) 그래프 및 축 제목, labs() 함수

> labs ( x = "x축 이름", y = "y축 이름", title = "그래프 제목")

```R
# mtcars 데이터셋에서 변속기 기어 수에 따른 빈도를 막대그래프로 표현하고 그래프 제목과 각 축의 이름 추가해보기

> ggplot(mtcars, aes(x=gear)) + geom_bar() + # 막대그래프 그리기
    labs(x="기어수", y="자동차수", title="변속기 기어별 자동차수") # 제목 추가
```

![10](190911%20R.assets/10.JPG)



#### 2) 테마 적용, theme() 함수

```R

```



---

## VI. 크롤링

- read_html() : url에서 html 파일을 읽어오고 저장한다.
- html_table() :  테이블추출
- html_node()는 매칭되는 한 요소만 반환하고, html_nodes()는 모든 요소를 반환한다. id를 찾을 경우에는 html_node()를 사용하면 되고, tag, class로 같은 요소를 모두 추출하고자 할 경우에는 html_nodes()를 사용하면 된다.
- html_names()는 attribute의 이름을 가져온다.    
  ex) <img src="....">
- html_chidren() 해당 요소의 하위 요소를 읽어온다.
- html_tag() tag이름 추출한다.
- html_attrs() attribute을 추출한다.



### 1. 실습

#### 1) 패키지 설치 및 적용

```R
> install.packages('rvest')
> library(rvest)
```



#### 2) 웹사이트 URL 저장하고 HTML 코드 읽기

```R
#스크래핑할 웹 사이트 URL을 변수에 저장
> url <- 'http://www.imdb.com/search/title? count=100&release_date=2016,2016&title_type=feature'

#웹 사이트로부터  HTML code 읽기
> webpage <- read_html(url)   # html 내용으로 돼있음
> webpage
{html_document}
<html xmlns:og="http://ogp.me/ns#" xmlns:fb="http://www.facebook.com/2008/fbml">
[1] <head>\n<meta http-equiv="Content-Type" ...
[2] <body id="styleguide-v2" class="fixed"> ...
```



#### 3) 랭킹 데이터 가져오기

```R
# 랭킹이 포함된 CSS 셀렉터를 찾아서 R 코드로 가져오기
> rank_data_html <- html_nodes(webpage, '.text-primary')

# 랭킹 데이터를 텍스트로 가져오기
> rank_data <- html_text(rank_data_html)
> head(rank_data)
[1] "1." "2." "3." "4." "5." "6."

# 랭킹 데이터를 수치형 데이터로 변환
> rank_data <- as.numeric(rank_data)
> head(rank_data)
[1] 1 2 3 4 5 6
> str(rank_data)
 num [1:100] 1 2 3 4 5 6 7 8 9 10 ...
> length(rank_data)
[1] 100
```



#### 4) 제목 데이터 가져오기

```R
# 제목 영역의 CSS selector 스크랩핑
> title_data_html <- html_nodes(webpage, '.lister-item-header a')

# 제목 데이터 텍스트로 가져오기
> title_data <- html_text(title_data_html)
> head(title_data)
[1] "Suicide Squad"     "London Has Fallen"
[3] "X-Men: Apocalypse" "Deadpool"         
[5] "Split"             "Rogue One"        
> length(title_data)
[1] 100
```



#### 5) Description 데이터 가져오기

```R
# description 영역의 CSS selectors 스크래핑
> descript_data_html <- html_nodes(webpage, '.ratings-bar + .text-muted')
# <div>ratings-bar</div> 아래의 <p class=text-muted> 를 불러오는 것

# description 데이터 텍스트로 가져오기
> descript_data <- html_text(descript_data_html)

# '\n' 제거
> descript_data <- gsub("\n", "", descript_data)

# 앞, 뒤 공백 제거
> library(stringr)
> descript_data <- str_trim(descript_data)

> head(descript_data)
[1] "A secret government agency recruits some of the most dangerous incarcerated super-villains to form a defensive task force. Their first mission: save the world from the apocalypse."
[2] "In London for the Prime Minister's funeral, Mike Banning is caught up in a plot to assassinate all the attending world leaders."                                                    
[3] "In the 1980s the X-Men must defeat an ancient all-powerful mutant, En Sabah Nur, who intends to thrive through bringing destruction to the world."                                  
[4] "A wisecracking mercenary gets experimented on and becomes immortal but ugly, and sets out to track down the man who ruined his looks."                                              
[5] "Three girls are kidnapped by a man with a diagnosed 23 distinct personalities. They must try to escape before the apparent emergence of a frightful new 24th."                      
[6] "The daughter of an Imperial scientist joins the Rebel Alliance in a risky move to steal the Death Star plans."  
```



#### 6) 상영시간 데이터 가져오기

```R
#영화 상영시간 CSS selectors 스크래핑
runtime_data_html <- html_nodes(webpage,'.text-muted .runtime')

#영화 상영시간 데이터 텍스트로 가져오기
runtime_data <- html_text(runtime_data_html)
head(runtime_data)

#mins(분) 문자열 제거 후 수치형 데이터로 변환 데이터 처리
runtime_data<-gsub(" min","",runtime_data)
runtime_data<-as.numeric(runtime_data)
> head(runtime_data)
[1] 123  99 144 108 117 133
```



#### 7) 장르 데이터 가져오기

```R
# 영화장르 영역 CSS selectors 스크래핑
> genre_data_html <- html_nodes(webpage,'.genre')


# 영화장르 데이터 텍스트로 가져오기
> genre_data <- html_text(genre_data_html)
> head(genre_data)
[1] "\nAction, Adventure, Fantasy            "
[2] "\nAction, Thriller            "          
[3] "\nAction, Adventure, Sci-Fi            " 
[4] "\nAction, Adventure, Comedy            " 
[5] "\nHorror, Thriller            "          
[6] "\nAction, Adventure, Sci-Fi            " 


# \n 제거 데이터 처리
> genre_data<-gsub("\n","",genre_data)
> head(genre_data)
[1] "Action, Adventure, Fantasy            "
[2] "Action, Thriller            "          
[3] "Action, Adventure, Sci-Fi            " 
[4] "Action, Adventure, Comedy            " 
[5] "Horror, Thriller            "          
[6] "Action, Adventure, Sci-Fi            " 


# 1개이상의 공백을 제거하는 데이터 처리
> genre_data<-gsub(" ","",genre_data)
> head(genre_data)
[1] "Action,Adventure,Fantasy"
[2] "Action,Thriller"         
[3] "Action,Adventure,Sci-Fi" 
[4] "Action,Adventure,Comedy" 
[5] "Horror,Thriller"         
[6] "Action,Adventure,Sci-Fi" 


# 장르는 첫번째 장르문자열만 남기고 모두 제거
> genre_data<-gsub(",.*","",genre_data)
> head(genre_data)
[1] "Action" "Action" "Action" "Action"
[5] "Horror" "Action"
> genre_data
  [1] "Action"    "Action"    "Action"   
  [4] "Action"    "Horror"    "Action"   
  [7] "Adventure" "Comedy"    "Biography"
 [10] "Comedy"    "Animation" "Biography"
 [13] "Action"    "Action"    "Action"   
 [16] "Drama"     "Drama"     "Action"   
 [19] "Animation" "Action"    "Drama"    
 [22] "Animation" "Drama"     "Drama"    
 [25] "Comedy"    "Animation" "Biography"
 [28] "Action"    "Crime"     "Crime"    
 [31] "Drama"     "Adventure" "Action"   
 [34] "Action"    "Comedy"    "Drama"    
 [37] "Horror"    "Drama"     "Action"   
 [40] "Biography" "Drama"     "Action"   
 [43] "Horror"    "Animation" "Drama"    
 [46] "Crime"     "Drama"     "Drama"    
 [49] "Action"    "Action"    "Action"   
 [52] "Action"    "Biography" "Action"   
 [55] "Adventure" "Action"    "Horror"   
 [58] "Action"    "Action"    "Adventure"
 [61] "Horror"    "Horror"    "Action"   
 [64] "Animation" "Horror"    "Animation"
 [67] "Comedy"    "Action"    "Action"   
 [70] "Action"    "Comedy"    "Action"   
 [73] "Horror"    "Biography" "Animation"
 [76] "Comedy"    "Comedy"    "Action"   
 [79] "Action"    "Comedy"    "Action"   
 [82] "Drama"     "Drama"     "Drama"    
 [85] "Drama"     "Animation" "Biography"
 [88] "Action"    "Action"    "Comedy"   
 [91] "Drama"     "Action"    "Action"   
 [94] "Action"    "Animation" "Animation"
 [97] "Action"    "Action"    "Action"   
[100] "Action"   


# 문자열 데이터를 범주형 데이터로 변환 처리
> genre_data<-as.factor(genre_data)
> head(genre_data) 
[1] Action Action Action Action Horror Action
8 Levels: Action Adventure ... Horror
```



#### 8) IMDB rating 데이터 가져오기

```R
# IMDB rating 영역의 CSS selectors를 이용한 스크래핑
> rating_data_html <- html_nodes(webpage,'.ratings-imdb-rating strong')

# IMDB rating 데이터 text로 가져오기
> rating_data <- html_text(rating_data_html)
> head(rating_data) 
[1] "6.0" "5.9" "6.9" "8.0" "7.3" "7.8"

# IMDB rating 데이터를 numerical으로 변환 데이터 처리
> rating_data<-as.numeric(rating_data)
> head(rating_data)
[1] 6.0 5.9 6.9 8.0 7.3 7.8
```



#### 9) Vote 데이터 가져오기

```R
# votes 영역의 CSS selectors를 이용한 스크래핑
votes_data_html <- html_nodes(webpage, '.sort-num_votes-visible span:nth-child(2)') 
# 해당 단락 태그의 span태그의 2번째 자식을 가져오기

# votes 데이터 text로 가져오기
votes_data <- html_text(votes_data_html)

# 콤마 제거 데이터 처리
> votes_data <- gsub(",", "", votes_data)

# numerical로 형변환
> votes_data <- as.numeric(votes_data)
> head(votes_data)
[1] 544063 128895 365202 836193 371465 487689
```



#### 10) 감독, 배우 데이터 가져오기

```R
# 감독 영역의 CSS selectors를 이용한 스크래핑
> director_data_html <- html_nodes(webpage,
                                  '.text-muted+ p a:nth-child(1)')


# 감독 데이터 text로 가져오기
> director_data <- html_text(director_data_html)
> head(director_data)
[1] "David Ayer"         "Babak Najafi"      
[3] "Bryan Singer"       "Tim Miller"        
[5] "M. Night Shyamalan" "Gareth Edwards"


# 감독 데이터 문자열을  범주형 데이터로 변환 처리
> director_data<-as.factor(director_data)
> head(director_data)
[1] David Ayer         Babak Najafi      
[3] Bryan Singer       Tim Miller        
[5] M. Night Shyamalan Gareth Edwards   
99 Levels: Adam Wingard ... Zack Snyder


# 배우 영역의 CSS selectors를 이용한 스크래핑
> actors_data_html <- html_nodes(webpage,
                  '.lister-item-content .ghost+ a')


# 배우 데이터 text로 가져오기
> actors_data <- html_text(actors_data_html)
> head(actors_data)
[1] "Will Smith"     "Gerard Butler" 
[3] "James McAvoy"   "Ryan Reynolds" 
[5] "James McAvoy"   "Felicity Jones"


#배우 데이터 문자열을 범주형 데이터로 변환 처리
> actors_data<-as.factor(actors_data)
> head(actors_data)
[1] Will Smith     Gerard Butler 
[3] James McAvoy   Ryan Reynolds 
[5] James McAvoy   Felicity Jones
90 Levels: Aamir Khan ... Zac Efron
```



#### 11) 메타스코어 데이터 가져오기

```R
# metascore 영역의 CSS selectors를 이용한 스크래핑
> metascore_data_html <- html_nodes(webpage,'.metascore')

# metascore 데이터 text로 가져오기
> metascore_data <- html_text(metascore_data_html)
> head(metascore_data)
[1] "40        " "28        " "52        "
[4] "65        " "62        " "65        "
 

#1개 이상의 공백 제거
> metascore_data<-gsub(" ","",metascore_data)
> length(metascore_data)
[1] 96
> metascore_data
 [1] "40" "28" "52" "65" "62" "65" "66" "76"
 [9] "71" "93" "61" "57" "44" "35" "75" "51"
[17] "81" "70" "79" "72" "67" "81" "99" "41"
[25] "72" "59" "78" "33" "48" "84" "57" "60"
[33] "51" "72" "62" "35" "59" "58" "74" "76"
[41] "32" "51" "78" "42" "71" "79" "96" "68"
[49] "88" "44" "54" "69" "72" "77" "48" "65"
[57] "42" "81" "65" "67" "25" "66" "47" "43"
[65] "60" "33" "36" "49" "77" "42" "74" "56"
[73] "51" "90" "52" "60" "64" "46" "81" "23"
[81] "43" "58" "77" "66" "63" "32" "82" "64"
[89] "45" "22" "36" "34" "38" "66" "23" "47"

#metascore 누락된 데이터  NA처리하기  - 29,58, 73, 96
> for (i in c(29,58, 73, 96)){
  a<-metascore_data[1:(i-1)]    #리스트로 확인
  b<-metascore_data[i:length(metascore_data)]
  metascore_data<-append(a,list("NA"))
  metascore_data<-append(metascore_data,b)
  }
> head(metascore_data)
[[1]]
[1] "40"

[[2]]
[1] "28"

[[3]]
[1] "52"

[[4]]
[1] "65"

[[5]]
[1] "62"

[[6]]
[1] "65"

# metascore  데이터를 numerical으로 변환 데이터 처리
> metascore_data<-as.numeric(metascore_data)

# metascore  데이터 개수 확인
> length(metascore_data) 
[1] 100

#metascore 요약 통계 확인
> summary(metascore_data)
   Min. 1st Qu.  Median    Mean 3rd Qu. 
  22.00   44.75   60.50   59.05   72.00 
   Max.    NA's 
  99.00       4 
```



#### 12) 총수익 데이터 가져오기

```R
# gross revenue(총수익)  영역의 CSS selectors를 이용한 스크래핑
> gross_data_html <- html_nodes(webpage,'.ghost~ .text-muted+ span')

#gross revenue(총수익) 데이터 text로 가져오기
> gross_data <- html_text(gross_data_html)
> head(gross_data)
[1] "$325.10M" "$62.68M"  "$155.44M"
[4] "$363.07M" "$138.29M" "$532.18M"
 
# '$' 와 'M' 기호 제거 데이터 처리
> gross_data<-gsub("$","",gross_data)
> gross_data<-gsub("M","",gross_data)
> gross_data<-substring(gross_data,2,6)

#gross revenue(총수익) 데이터 개수 확인
> length(gross_data)
[1] 93

# 누락된 데이터  NA로 채우기 - 29,45,57,62,73,93,98
> for (i in c(29,45,57,62,73,93,98)){
  a<-gross_data[1:(i-1)]
  b<-gross_data[i:length(gross_data)]
  gross_data<-append(a,list("NA"))
  gross_data<-append(gross_data,b)
  }

# gross revenue(총수익) 데이터를 numerical으로 변환 데이터 처리
> gross_data<-as.numeric(gross_data)

#gross revenue(총수익) 데이터 개수 확인
> length(gross_data)
[1] 100

#gross revenue(총수익) 요약 통계 확인 
> summary(gross_data)
   Min. 1st Qu.  Median    Mean 3rd Qu. 
   0.18   12.79   54.65   95.02  125.00 
   Max.    NA's 
 532.10       7 
```



#### 13) 시각화

```R
#data.frame으로 변환
> movies_df<-data.frame(Rank = rank_data, Title = title_data,
  Description = description_data, Runtime = runtime_data,
  Genre = genre_data, Rating = rating_data,
  Metascore = metascore_data, Votes = votes_data,   
  Director = directors_data, Actor = actors_data,
  Gross = gross_data)

> str(movies_df)
'data.frame':	100 obs. of  11 variables:
 $ Rank       : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Title      : Factor w/ 100 levels "10 Cloverfield Lane",..: 71 49 100 25 69 64 67 95 33 45 ...
 $ Description: Factor w/ 100 levels "A blind woman's relationship with her husband changes when she regains her sight and discovers disturbing detai"| __truncated__,..: 20 62 64 24 86 79 76 8 100 97 ...
 $ Runtime    : num  123 99 144 108 117 133 132 117 139 128 ...
 $ Genre      : Factor w/ 8 levels "Action","Adventure",..: 1 1 1 1 8 1 2 5 4 5 ...
 $ Rating     : num  6 5.9 6.9 8 7.3 7.8 7.3 6.8 8.1 8 ...
 $ Metascore  : num  40 28 52 65 62 65 66 76 71 93 ...
 $ Votes      : num  544063 128895 365202 836193 371465 ...
 $ Director   : Factor w/ 99 levels "Adam Wingard",..: 28 12 16 95 62 39 32 61 67 24 ...
 $ Actor      : Factor w/ 90 levels "Aamir Khan","Adam Driver",..: 88 34 38 72 38 31 24 33 6 71 ...
 $ Gross      : num  325.1 62.7 155.4 363 138.2 ...

# 상영시간 기준으로 시각화
> qplot(data = movies_df, Runtime, fill = Genre, bins = 30)
```

![19](190911%20R.assets/19.JPG)



```R
# 상영시간이 가장 긴 필름의 장르는?
> ggplot(movies_df, aes(x=Runtime, y=Rating))+
    geom_point(aes(size=Votes, col=Genre))
```

![20](190911%20R.assets/20.JPG)



```R
# 상영시간이 130-160분인 장르중 votes가 가장 높은 것은?
> ggplot(movies_df, aes(x=Runtime, y=Rating))+
    geom_point(aes(size=Votes, col=Genre))+
    annotate("rect", xmin=130, xmax=160, ymin=5, ymax=9, alpha=0.3, fill="gray")
```

![21](190911%20R.assets/21.JPG)



cf) 연습문제

```R
##############################################
가격 비교를 위한 스크래핑
rvest 패키지 : 웹 페이지에서 필요한 정보를 추출하는데 유용한 패키지
selectr패키지, xml2 패키지가 의존 패키지이므로 함께 설치
read_html(url) : 지정된 url에서 html 컨텐츠를 가져옵니다.
jsonline 패키지 : json 파서/생성기가 웹용으로 최적화되어 있는 패키지
##############################################
install.packages("jsonlite")
libary(jsonlite)
libary(xml2)
libary(rvest)
libary(stringr)

url <- 'https://www.amazon.in/OnePlus-Mirror-Black-64GB-Memory/dp/B0756Z43QS?tag=googinhydr18418-21&tag=googinkenshoo-21&ascsubtag=aee9a916-6acd-4409-92ca-3bdbeb549f80'

#추출할 정보 : 제목, 가격, 제품 설명, 등급, 크기, 색상
```

