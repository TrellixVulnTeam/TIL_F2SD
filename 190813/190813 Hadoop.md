# 190813 Hadoop

**#하둡의 정의** : 신뢰성 있고, 확장성 있는 분산 컴퓨팅을 위한 오픈소스 프레임워크

=> 간단한 프로그래밍 모델을 사용해 대용량 데이터의 분산 처리를 할 수 있는 프레임워크



**#하둡의 특징**

- 대용량 데이터 처리 능력
  - 분산파일시스템(HDFS) : 어플리케이션 데이터에 고성능 접근을 지원하는 분산 파일 시스템
  - 분산병렬처리시스템(MapReduce) : 대용량 데이터의 병렬처리를 위한 얀 기반 시스템
  - 기반소프트웨어프레임워크(Core)
- 장애를 허용 : 하둡은 하드웨어가 장애가 발생할 수 있다는 것을 전제로 모든 것이 설계 돼 있음
- 높은 장애 대응력
- 데이터의 스트리밍 액세스 : 랜덤 액세스는 seek time이 오래 걸리고 성능에도 영향을 주는 반면 hadoop은 sequential하게 파일을 쓰고 읽는 방식이어서 이 부분에서만큼은 빠름. => 장점 : 배치 프로세싱에 적합
- 간단한 데이터 일관성 모델(Simple data consistency model) : WORM모델(Write-Once-Read-Many access)



**#HDFS(Hadoop Distributed File System)**

- 파일의 분산 저장이 목적

- Namenodes와 Datanodes로 구성
  - Master Namenode
  - Secondary Namenode
  - Datanode

-  저렴한 컴퓨터로 대 용량 데이터를 저장할 수 있는 시스템
  - 네트워크 Raid와 같이 연결된 것 처럼 사용하는 하드디스크

  - Scale Out : 데이터 사이즈가 커질수록 서버를 계속 추가시켜 전체적인 저장능력을 증가시키는 방식

-  Block(Chunk) 단위로 파일관리 (저장/복제/삭제)
  - Default Size는 64M

- 복제기능을 통해 안전성/신뢰성을 보장

-  1대의 Master서버에 4000+이상의 Datanodes를 운영할 수 있음.

- API지원
  - 하둡 코어는 Python, Java, C/C++



**#하둡의 장점**

- 전통적인 정형화 데이터를 저장하고 처리할 뿐만 아니라 일부만 정형화되거나 완전 비정형 데이터도 저장하고 처리할 수 있다.
- 사실상 무제한으로 데이터를 저장할 수 있다. 그리고 그 데이터들을 분석할 수 있는 여러 개의 프로세싱 프레임워크를 지원한다.
- SQL과 NoSQL 프로세싱 프레임워크를 사용할 수 있다. 또한 병렬 처리 프로세싱 전략을 사용해 저장돼 있는 방대한 데이터세트를 효과적으로 처리할 수 있다.
- 범용 서버를 사용하고 하둡 환경의 거의 모든 요소가 오픈 소스 소프트웨어이기 때문에 비용에 있어 효율적이다.
- 데이터 분석을 하기 위해 만들어졌다. 하둡은 방대한 양의 데이터세트를 저장하고 프로세싱할 수 있도록 디자인됐다.



**#하둡 클러스터** : 하둡이 실행되는 머신들과 그 머신이 데이터를 저장하고 프로세싱하도록 하는 운영 시스템인 데몬, 소프트웨어 프로세스들로 구성



**#분산 파일 시스템**

- 큰 데이터 블록 사용 : 방대한 데이터 청크들을 신속하게 처리하기 위해서
- 데이터 중복성 : 파일 시스템이 저렴한 프로세싱 노드들을 사용하므로 언제든지 장애가 일어날 수 있기 때문에 데이터가 다수의 서버에 걸쳐 복제되는 것



**#하둡 컴포넌트들과 하둡 생태계**

- 하둡 공통 : 하둡 환경에서 나머지의 모듈들을 지원하는 기본 유틸리티들
  - 운영 시스템 인증이나 파일 시스템과 같은 하둡 클러스터를 위한 필수 서비스
  - 클러스터 시작 스크립트들이나 그 스크립트들을 위해 필요한 자바 파일
  - 문서
  - 하둡 프레임워크의 소스 코드
- HDFS : 데이터에 접속해 높은 처리량을 보여주는 파일 시스템 => 데이터 스토리지
- 하둡 얀 : 작업을 스케쥴링하고 리소스를 관리하는 프레임워크 => 운영시스템
- 하둡 맵리듀스 : 크기가 큰 데이터 세트를 병렬 처리하기 위한 프레임워크  => 데이터 프로세싱



**#하둡 관련 프로젝트 분류**

- 하둡 공통 : 기본 유틸리티
- 데이터 스토리지 : HDFS에 의해 제공된다. HBase는 구조화된 데이터의 저장을 위해 많은 테이블들을 제공한다.
- 운영 시스템 : YARN. 리눅스와 같은 실제 서버의 운영체제 위에 설치돼 작업들을 스케쥴링하고 리소스를 관리
- 데이터 프로세싱 : 크기가 큰 데이터 세트의 분산 데이터 처리를 의미한다. 하둡의 맵리듀스, 아파치 테즈, 스파크 컴퓨팅 엔진들이 이러한 기능을 제공
- 관리 툴과 코디네이터 서비스 : 암바리(Ambari)는 하둡의 관리 및 모니터링 툴이고, 주키퍼는 분산 애플리케이션의 작업을 조직화하는 아파치의 구성 요소다.



![1565684715487](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565684715487.png)



**#하둡 관리자가 하는 일**

- 설치와 업그레이드
  - 가상 분산 시스템 : 단일 노드에 하둡 환경을 설치하는 것
- 성능 튜닝(최적화) : 메모리나 CPU동작을 포함한 서버 레벨의 실행 문제를 능숙하게 해결할 수 있어야 함
- 모니터링과 트러블 슈팅



**#분산형 데이터 처리**

- 맵리듀스 : 분산 프로세싱 프레임워크로 자바 프로그램들을 작성해 HDFS에 저장한 데이터를 처리할 수 있다. 맵리듀스 프레임워크가 맵과 리듀스 기능을 제외한 모든 프로세싱 로직을 맡아 처리해주기 때문에 맵리듀스 프레임워크를 이용해 병렬 분산 애플리케이션을 작성할 때 복잡한 로직들이 단순해진다.
  - 수백, 수천개의 노드로 구성된 커다란 클러스터를 사용
  - 맵 단계 : 데이터를 키/값 쌍 형태로 만드는 작업을 수행
  - 리듀스 단계 : 맵 단계에서 만든 키/값 쌍을 받은 후, 특정 알고리즘을 적용해 우리가 원하는 최종 결과를 만든다. 

- 아파치 스파크 : 분석적인 작업을 수행할 때 소스가 되는 데이터들을 이해하기 위해 여러가지 데이터 소스를 사용하게 되는 경우가 있는데 이럴 때 스파크를 하둡 위에서 동작시키면 맵리듀스 잡과 스파크 잡을 같은 클러스터와 같은 데이터로 사용할 수 있다.
  - 맵리듀스는 반복적 알고리즘 프로세싱 방식의 문제 + interactive한 작업에 적합하지 않다는 문제를 가짐. 스파크는 interactive한 쿼리와 반복적인 알고리즘을 신속하게 처리할 수 있게 해준다.
- 아파치 하이브 : SQL 인터페이스를 제공해 맵리듀스를 사용한 프로그램을 작성할 필요 없이 HDFS 데이터를 사용할 수 있게 해준다. 
  - HBase와 달리, 데이터베이스가 아니다!
  - HiveQL을 사용해 interactive하게 데이터베이스에 저장된 데이터 쿼리를 처리하는 방식!
- 아파치 피그 : 데이터 프로세싱을 위한 고수준 프레임워크
  - 맵리듀스를 사용한 데이터를 처리하며 데이터 연산을 위한 다양한 타입을 사용할 때 좋음
  - 절차식 언어로 데이터 파이프 라이닝에 적합. 데이터 분석 문제를 데이터 흐름으로 표현한다.



**#데이터 통합**

- 스쿱 : 하둡 환경에서 데이터를 관계형 데이터베이스에서 HDFS 또는 그 반대로 이동하는 대표적인 툴
- 플룸, 아파치 카프카 : 큰 볼륨의 로깅 데이터는 데이터를 실시간으로 프로세싱하려고 할 때 문제가 발생하는데, 플룸과 아파치 카프카는 클러스터가 간혈적으로 증가되는 로깅 데이터들도 처리할 수 있도록 해준다.
  - 아파치 플룸 : 많은 양의 스트리밍 데이터를 수집, 종합하고 다양한 소스로부터 HDFS 같은 데이터 저장소로 이동하는 시스템
  - 아파치 카프카 : 하둡 시스템으로 병렬 로딩을 가능하게 하고, 실시간 데이터 소비를 클러스터로 분할해줌으로써 오프라인과 온라인 스트리밍 데이터 처리를 결합할 수 있다.