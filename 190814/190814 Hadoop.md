# 190814 Hadoop

## 복습

**#번호별 모드**

- 0 : 시스템 종료 - /etc/rc0.d

- 1, S : 응급 복구 모드 (싱글 사용자 모드) - /etc/rc1.d

- 2, 3, 4 : 다중 사용자 모드

- 5 : 그래피컬 다중 사용자 모드

- 6 : 재시작



**#리눅스 종료**

 : poweroff, shutdown, halt, init 0, init 6, reboot



**#파일 아카이브 관련(tar)**

- 파일을 묶어서 하나로 만드는 것 : 파일 아카이브

- 다른 시스템과 파일을 주고 받거나, 백업을 하기 위해 여러 파일이나 디렉토리를 하나의 아카이브 파일로 생성, 추출, 업데이트하는 명령 : tar

- 새 아카이브 생성 : tar cvf
- 아카이브 파일 내용 확인 : tar tvf
- 아카이브 풀기 : tar xvf
- 아카이브 업데이트 : tar uvf
- 아카이브에 파일 추가 : tar rvf
- 아카이브를 생성, 동시에 압축 : tar cvzf (gzip), tar cvjf(bzip2)
- 압축하기/압축풀기 : gzip / gunzip (.gz) , bzip2 / bunzip2 (.bz)
- 압축 파일의 내용 보기 : zcat / bcat  



**#계정정보 파일 관련**

- 사용자 계정 정보가 저장된 기본 파일 : /etc/passwd

- 사용자 계정의 암호화된 비밀번호 정보가 저장된 기본 파일 : /etc/shadow

- 사용자가 속한 그룹 정보가 저장된 기본 파일 : /etc/group
- 사용자가 속한 그룹의 암호화된 비밀번호 정보가 저장된 기본 파일 : /etc/gshadow



**#사용자 계정/그룹 관련**

- 사용자 계정 생성 : useradd, adduser
- 사용자 계정 정보 수정 :  usermod
- 사용자 계정 삭제 : userdel
- 사용자 계정의 패스워드 에이징 관리 : change
- 사용자 그룹 생성 : groupadd, addgroup
- 사용자 그룹 정보 수정 : groupmod
- 사용자 그룹 삭제 : groupdel

- 사용자 로그인 정보 확인 : who
- 사용자 이름, 로그인 한 시간, 로그아웃 시간, 터미널번호, IP주소 확인 : last
- 사용자가 소속된 그룹 확인 : groups
- 파일이나 디렉토리의 소유자, 그룹 변경 
  - chown -R 소유자:그룹 ~
  - chown 소유자 ~
  - chgrp 그룹~



**#빅데이터 6V**

- 크기(Volume) : 방대한 양의 데이터(테라, 페타바이트 이상의 크기)

- 다양성(Varity) : 정형(DBMS, 전문 등) + 비정형(SNS, 동영상, 사진, 음성, 텍스트 등)

- 속도(Velocity) : 실시간으로 생산되며, 빠른 속도로 데이터를 처리/분석

- 진실성(Veracity) : 주요 의사결정을 위해 데이터 품질과 신뢰성 확보

- 시각화(Visualization) : 복잡한 대규모 데이터를 시각적으로 표현

- 가치(Value) : 비즈니스 효익을 실현하기 위해 궁극적인 가치를 창출



**#Hadoop** : 오픈소스 분산 병렬 (파일 시스템) 프레임워크

- HDFS, MapReduce, YARN, Core, 여러 API
- 클러스터 : Master-Slave 구조
  - NameNode : 전체 HDFS의 namespace, meta정보가 저장됨
  - DataNode : 기본 설정이 64mb(128mb도 가능), 데이터 블럭이 분산되어 저장됨
  - 3개 데이터 블럭은 복제되어 저장 : 장애 허용, 대응력 높음



-----------------



**#Hadoop의 Exercising Process**

: NameNode의 Job Tracker가 데이터가 분산 저장돼 있는 DataNode를 검색을 해서 분산돼 있는 데이터에 대해 Map작업을 해줄 Task Tracker를 실행을 시킴. 그러면 각각의 데이터에 대해서 Key, Value형태를 만들고 이를 다시 데이터 노드에 저장을 함. 같은 key의 데이터를 sorting을 하고 sorting된 데이터를 다시 나눠서 작업을 하도록 shuffle을 함. 그러고 다시 배치시켜서 같은 key를 가지고 있는 데이터의 value값들에 대한 통계 작업, Reduce 작업을 함. 이렇게 Reduce 작업이 끝난 걸 결과로 데이터를 끌어오는 것.





**#하둡 배포판**

- 클라우데라 
  - CDH 관리시스템이 우월하다
  - 임팔라(Impala) , 스파크(Spark) 등을 전략적으로 포함
  - 관리가 중요하다고 하면 클라우데라 CDH를 사용하는 것이 권장된다.
  - Hive, Pig 등 Hadoop 연동 제품 패키지, 동작 검증, 가동 스크립트 등 유틸리티 제공

- 호튼웍스 HDP
  - 가장 오픈소스처럼 사용하는 것을 중요하게 생각한다면 선택해야 할 배포판 버전업이 빠른 것이 장점
  - 감시계 소프트웨어를 포함해 모두 오픈 소스로 제공  

- 아파치 하둡
  - 단순하게 커스터마이징해서 사용하고자 하는 경우에 적당
- 맵알(MAPR)
  - 파일시스템의 성능이 중요한 선택 조건

- 피보탈 HD
  - EMC 어플라이언스 기반으로 국내 딜리버리가 이루어져있다.
  - 하둡 배포판 중에는 국내 가장 큰 레퍼런스를 다수 보유하고 있다.
  - 삼성반도체, 삼성SDI, 삼성디스플레이, 삼성전자 MSC 등이 주요 구축 사이트다.





**#하둡 애플리케이션의 이용 사례**

- 웹 접속 로그 통게 - 클릭 이력 축적 , 사용자 접속 경향 분석

- 전문 검색용 전치 인덱스 구축 – 어떤 단어가 어떤 문서에 존재하는가란 정보를 전치 인덱스라는 형태로 색인화

- 통계적 기계 번역

- 대용량 동영상 데이터의 포맷을 변환할 경우, 데이터를 작은 크기로 나누어 변환하고 변환 후에 데이터를 다시 결합하여 한 개의 파일로 만드는 처리

- 특정 패턴에 속하지 않는 이상값을 대량의 데이터에서 검출 처리 – 비자 리스크 관리를 위한 스코링 시스템, 야후 스팸 필터 학습

- 일정량의 데이터를 분석하고 그 데이터에서 의미있는 규칙이나 경향을 끄집어 내는 처리 – 음성인식이나 패턴 인식, 금융, 증권시장의 동향분석, 유전자 분석, 기상 예측, 교통 예측



**#하둡의 동작 과정 만화**

![1565746582701](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746582701.png)

![1565746610324](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746610324.png)

![1565746617508](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746617508.png)

![1565746622279](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746622279.png)

![1565746627156](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746627156.png)

![1565746631443](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746631443.png)

![1565746637500](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746637500.png)

![1565746641978](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746641978.png)

![1565746646206](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565746646206.png)





**#하둡 동작 모드**

- 로컬 모드

  - 한 대의 서버 상에 HDFS를 사용하지 않고 MapReduce 동작 환경을 구축하다

  - HDFS를 사용하지 않기 때문에 NameNode 프로세스, DataNode 프로세스로도 동작하지 않음

  - 단일 자바 프로세스로 실행되기 때문에 JobTracker 프로세스, TaskTracker 프로세스 모두 동작하지 않는다.

  - MapReduce 동작만 검증

- 유사분산모드
  - 한 대의 서버 상에 HDFS를 사용한 MapReduce 동작 환경을 구축한다.
  - NameNode 프로세스, DataNode 프로세스 모두 한 대의 서버 상에서 동작

  - JobTracker 프로세스, Task Tracker 프로세스 모두 한 대의 서버상에서 동작

  - HDFS/MapReduce 동작 검증, Hadoop 애플리케이션 기능 검증

- 완전 분산 모드 (얘로 실습 예정)

  - 여러 대의 서버 상에 HDFS를 사용한 MapReduce 동작환경을 구축한다.

  - 상용 환경 구축, 노드 간 통신을 포함한 HDFS/MapReduce 동작 검증, 성능 등의 비기능 요건을 포함한 애플리케이션 검즘





**#하둡 설치하기**

jdk랑 hadoop 설치하고 노드를 복제해서 원래 노드는 master노드로 복제한 노드는 slave1노드로 설정

master노드와 slave1 노드의 ip를 적어놓고 etc/hosts를 각각 아래와 같은 형식으로 바꿔준다.

- jdk & hadoop 설치

```
[hadoop@master ~]$ su -
Password: 
Last login: Wed Jul 31 13:04:07 EDT 2019 on pts/0
[root@master ~]# cd /usr/local
[root@master local]# pwd
/usr/local
[root@master local]# tar -xvf /home/hadoop/Downloads/jdk-8u221-linux-x64.tar.gz 
[root@master local]# chown -R hadoop:hadoop /usr/local/jdk1.8.0_221/
[root@master local]# ls -al


[root@master local]# tar -xvf /home/hadoop/Downloads/eclipse-jee-photon-R-linux-gtk-x86_64.tar.gz 
[root@master local]# ls -al
[root@master local]# chown -R hadoop:hadoop /usr/local/eclipse/
[root@master local]# ls –al

[root@master local]# tar -xvf /home/hadoop/Downloads/hadoop-2.7.7.tar.gz 
[root@master local]# chown -R hadoop:hadoop /usr/local/hadoop-2.7.7/
[root@master local]# ls –al
```





**#Hostname** **변경**

- CentOS를 처음 시작하면 다음과 같이 Hostname이 localhost로 설정됩니다.

- 관리해야될 서버가 한대라면 모르지만 여러대를 관리한다면 서버별로 hostname을 지정해 주는것이 좋다.

```
[root@master local]# hostname
```

위 처럼 실행하면 현재 hostname을 확인할 수 있습니다. 



- hostname변경 방법은 일회성 변경과 영구적 변경 방법이 있습니다.hostname 호스트네임 을 실행하고 hostname을 실행하면 변경된 hostname을 확인할 수 있습니다. 하지만 서버를 재시작 하는 경우 hostname이 기존 localhost로 변경될 것입니다. 영구적으로  hostname을 변경하기 위해서는 

```
[root@master ~]# hostnamectl set-hostname slave1
```

​		위 구문을 실행하면 서버가 재시장 되어도 변경된  hostname을 유지합니다.



- 서버를 재시작 하지 않아도 아래의 명령을 실행하고 실행중인 터미널을 닫고 다시 열면 hostname이 변경된것을 확인할 수 있습니다.

```
/bin/hostname -F /etc/hostname
```





**# .bashrc 환경설정**

```
[root@master local]# su hadoop
[hadoop@master local]$ cd ~
[hadoop@master ~]$ vi .bash_profile
```

![1565772121085](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772121085.png)

![1565772124316](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772124316.png)



**#master 노드를 복사해서 slave node 구성하고 hostname을 slave1으로 영구 변경합니다.**



#master ip확인

![1565772174819](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772174819.png)

```
root@master ~]# vi /etc/hosts
192.168.50.128  master
192.168.50.128  secondary
192.168.50.129  slave1
192.168.50.128  slave2
```



![1565772250603](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772250603.png)

```
[root@slave1 ~]# vi /etc/hosts
192.168.50.128  master
192.168.50.128  secondary
192.168.50.129  slave1
192.168.50.128  slave2
```





**#** **ssh 설정**

![1565772395594](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772395594.png)

- master 서버에서 ssh  공개키 비밀키 생성

- 키 생성 암호화 알고리즘  rsa

- master와 slave 노드간의 데이터 전송에 사용됨





#slave노드에 배포할 공개키를 인증키로 복사

![1565772406100](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772406100.png)





#slave에서 ssh 설정

- Hadoop  home 디렉토리아래 ssh 디렉토리 생성 후 접근 권한 변경

```
[hadoop@slave1 ~]$ mkdir .ssh
[hadoop@slave1 ~]$ chmod 755 ~/.ssh
```



- master 서버에서 공개 키 분배

```
[hadoop@master ~]$ scp ~/.ssh/authorized_keys hadoop@192.168.50.129:./.ssh/

```



- slave 노드에 인증 키 복제 되었는지 확인

```
[hadoop@slave1 ~]$ ls .ssh/
```



- master 노드에서 테스트

```
[hadoop@master ~]$ ssh hadoop@master date
[hadoop@master ~]$ ssh hadoop@secondary date
[hadoop@master ~]$ ssh hadoop@slave1 date
[hadoop@master ~]$ ssh hadoop@slave2 date
```





- hadoop-env.sh
  - 하둡을 실행하는 쉘 스크립트 파일에서 필요한 환경변수를 설정합니다. 
  - 하둡 홈 디렉토리의 아래에 있는 bin 디렉토리에 있는 쉘 스크립트 파일이 hadoop-env.sh 를 사용합니다. 
  - JDK경로, 클래스 패스, 데몬 실행 옵션 등 다양한 환경 변수를 설정할 수 있습니다.

![1565772513616](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772513616.png)



- slaves
  - 데이터 노드를 실행할 서버를 설정합니다. 
  - 데이터 노드가 여러 개라면 라인단위로 서버이름을 설정하면 됩니다.

![1565772519969](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772519969.png)



- core-site.xml
  - HDFS와 맵리듀스에서 공통적으로 사용할 환경정보 설정합니다. 

  - hadoop-core-1.0.3.jar 파일에 포함되어 있는 core-default.xml을 오버라이드 한 파일입니다. 
  - core-site.xml에 설정 값이없을 경우 core-default.xml에 있는 기본 값을 사용합니다.

  - /usr/local/hadoop-2.7.7 경로 아래 tmp 디렉토리 생성 

![1565772550659](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772550659.png)



- hdfs-site.xml
  - HDFS에서 사용할 환경 정보를 설정합니다. 

  - hadoop-core-1.0.3.jar 파일에 포함되어 있는 hdfs-default.xml을 오버라이드 한 파일입니다. 
  - hdfs-site.xml에 설정 값이 없을 경우 hdfsdefault.xml에 있는 기본 값을 사용합니다.
  - dfs.replication - 데이터 복제 수를 결정함, 디폴트는 3, 실습환경에서 데이터 노드가 2개이므로 복제 수는 1로 설정한다.
  - dfs.permissions.enabled - true로 하면 HDFS에서 권한을 체크하며, false로 하면 권한 체크를 해제 한다. 디폴트는 true, false로 설정
  - dfs.secondary.http.address - 보조 네임노드의 주소와 포트 번호 지정, 디폴트는  0.0.0.0:50090, secondary:50090로 설정

  ![1565772589003](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772589003.png)

  

  

- mapred-site.xml
  - 맵리듀스에서 사용할 환경정보를 설정합니다. 
  - hadoop-core-1.0.3.jar 파일에 포함되어 있는 mapred-default.xml을 오버라이드 한 파일입니다. 

  - mapred-site.xml에 설정 값이 없을 경우mapred-default.xml에 있는 기본 값을 사용합니다. 

![1565772597616](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772597616.png)

![1565772601865](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772601865.png)





-  yarn-site.xml
  - 맵리듀스 프레임워크에서 사용하는 셔플 서비스를 지정합니다.

![1565772615426](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772615426.png)

![1565772618186](C:\Users\student\AppData\Roaming\Typora\typora-user-images\1565772618186.png)